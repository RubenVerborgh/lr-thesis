<!DOCTYPE html>
<html lang="en" xml:lang="en" xmlns="http://www.w3.org/1999/xhtml">
  <head>
    <meta charset="utf-8" />
    <title>Decentralising Scholarly Communication</title>
    <meta content="width=device-width, initial-scale=1" name="viewport" />
    <link href="media/css/basic.css" media="all" rel="stylesheet" title="Basic" />
    <link href="media/css/thesis.css" media="all" rel="stylesheet alternate" title="Thesis" />
    <link href="media/css/lncs.css" media="all" rel="stylesheet alternate" title="LNCS" />
    <link href="media/css/acm.css" media="all" rel="stylesheet alternate" title="ACM" />
    <link href="media/css/do.css" media="all" rel="stylesheet" />
    <link href="media/css/font-awesome.min.css" media="all" rel="stylesheet" />
    <script src="scripts/simplerdf.js"></script>
    <script src="scripts/medium-editor.min.js"></script>
    <script src="scripts/do.js"></script>
  </head>

  <body about="" prefix="rdf: http://www.w3.org/1999/02/22-rdf-syntax-ns# rdfs: http://www.w3.org/2000/01/rdf-schema# owl: http://www.w3.org/2002/07/owl# xsd: http://www.w3.org/2001/XMLSchema# dcterms: http://purl.org/dc/terms/ dctypes: http://purl.org/dc/dcmitype/ foaf: http://xmlns.com/foaf/0.1/ pimspace: http://www.w3.org/ns/pim/space# cc: https://creativecommons.org/ns# skos: http://www.w3.org/2004/02/skos/core# prov: http://www.w3.org/ns/prov# mem: http://mementoweb.org/ns# qb: http://purl.org/linked-data/cube# schema: http://schema.org/ void: http://rdfs.org/ns/void# rsa: http://www.w3.org/ns/auth/rsa# cert: http://www.w3.org/ns/auth/cert# wgs: http://www.w3.org/2003/01/geo/wgs84_pos# bibo: http://purl.org/ontology/bibo/ sioc: http://rdfs.org/sioc/ns# doap: http://usefulinc.com/ns/doap# dbr: http://dbpedia.org/resource/ dbp: http://dbpedia.org/property/ sio: http://semanticscience.org/resource/ opmw: http://www.opmw.org/ontology/ deo: http://purl.org/spar/deo/ doco: http://purl.org/spar/doco/ cito: http://purl.org/spar/cito/ fabio: http://purl.org/spar/fabio/ oa: http://www.w3.org/ns/oa# as: https://www.w3.org/ns/activitystreams# ldp: http://www.w3.org/ns/ldp# solid: http://www.w3.org/ns/solid/terms# acl: http://www.w3.org/ns/auth/acl# dio: https://w3id.org/dio# rel: https://www.w3.org/ns/iana/link-relations/relation#" typeof="schema:CreativeWork sioc:Post prov:Entity">
    <main>
      <article about="" typeof="schema:ScholarlyArticle">
        <h1 property="schema:name">Decentralising Scholarly Communication</h1>

        <div id="authors">
          <dl id="author-name">
            <dt>Authors</dt>
            <dd id="Sarven-Capadisli" inlist="" rel="bibo:authorList" resource="http://csarven.ca/#i"><span about="" rel="schema:creator schema:publisher schema:author"><a about="http://csarven.ca/#i" href="http://csarven.ca/" property="schema:name" rel="schema:url" typeof="schema:Person"><span about="http://csarven.ca/#i"><span property="schema:givenName">Sarven</span> <span property="schema:familyName">Capadisli</span></span></a></span><sup>âœŠ</sup></dd>
          </dl>
        </div>

        <dl id="document-identifier">
          <dt>Identifier</dt>
          <dd><a href="https://linkedresearch.org/article/csarven.ca/decentralising-scholarly-communication" rel="owl:sameAs">https://linkedresearch.org/article/csarven.ca/decentralising-scholarly-communication</a></dd>
        </dl>

        <dl id="document-created">
          <dt>Created</dt>
          <dd><time content="2018-09-07T10:56:06.532Z" datatype="xsd:dateTime" datetime="2018-09-07T10:56:06.532Z" property="schema:dateCreated">2018-09-07</time></dd>
        </dl>

        <dl id="document-modified">
          <dt>Modified</dt>
          <dd><time content="2018-09-07T10:58:09.255Z" datatype="xsd:dateTime" datetime="2018-09-07T10:58:09.255Z" property="schema:dateModified">2018-09-07</time></dd>
        </dl>

        <dl id="document-latest-version">
          <dt>Latest Version</dt>
          <dd><a href="https://linkedresearch.org/article/csarven.ca/2192338e-67e0-4f71-b15c-1ed2a4e1622d" rel="rel:latest-version">https://linkedresearch.org/article/csarven.ca/2192338e-67e0-4f71-b15c-1ed2a4e1622d</a></dd>
        </dl>

        <dl id="document-predecessor-version">
          <dt>Predecessor Version</dt>
          <dd><a href="https://linkedresearch.org/article/csarven.ca/bdc19f9e-1e06-45ef-b714-e42fb458f14f" rel="rel:predecessor-version">https://linkedresearch.org/article/csarven.ca/bdc19f9e-1e06-45ef-b714-e42fb458f14f</a></dd>
        </dl>

        <dl id="document-timemap">
          <dt>TimeMap</dt>
          <dd><a href="https://linkedresearch.org/article/csarven.ca/decentralising-scholarly-communication.timemap" rel="mem:timemap">https://linkedresearch.org/article/csarven.ca/decentralising-scholarly-communication.timemap</a></dd>
        </dl>

        <dl id="document-license">
          <dt>License</dt>
          <dd><a href="https://creativecommons.org/licenses/by/4.0/" rel="schema:license" title="Creative Commons Attribution">CC BY 4.0</a></dd>
        </dl>

        <dl id="document-inbox">
          <dt>Notifications Inbox</dt>
          <dd><a href="https://linkedresearch.org/inbox/csarven.ca/2192338e-67e0-4f71-b15c-1ed2a4e1622d/" rel="ldp:inbox">https://linkedresearch.org/inbox/csarven.ca/2192338e-67e0-4f71-b15c-1ed2a4e1622d/</a></dd>
        </dl>

        <dl id="document-annotation-service">
          <dt>Annotation Service</dt>
          <dd><a href="https://linkedresearch.org/annotation/csarven.ca/bdc19f9e-1e06-45ef-b714-e42fb458f14f/" rel="oa:annotationService">https://linkedresearch.org/annotation/csarven.ca/bdc19f9e-1e06-45ef-b714-e42fb458f14f/</a></dd>
        </dl>

        <dl id="document-in-reply-to">
          <dt>In Reply To</dt>
          <dd><a href="https://linkedresearch.org/calls" rel="as:inReplyTo">Call for Linked Research</a></dd>
        </dl>

        <dl id="document-status">
          <dt>Document Status</dt>
          <dd prefix="pso: http://purl.org/spar/pso/" rel="pso:holdsStatusInTime" resource="#bdc19f9e-1e06-45ef-b714-e42fb458f14f"><span rel="pso:withStatus" resource="http://purl.org/spar/pso/draft" typeof="pso:PublicationStatus">Draft</span></dd>
        </dl>

        <div datatype="rdf:HTML" property="schema:description">
          <section id="control-yourself" inlist="" rel="schema:hasPart" resource="#control-yourself">
            <h2 property="schema:name">Control Yourself</h2>
            <div datatype="rdf:HTML" property="schema:description">
              <p>Throughout history, the complex connections between communication technologies and society transformed control structures of civilisations. Harold Innis and Marshall McLuhan argued that electronic media, unlike any other, compressed time and space, creating a <q>global village</q> as well as facilitating the influence and potential of centralised control.</p>

              <p id="cyberspace-independence">While the Internet reinforces democratic (re)distribution of communicative power, and the Web is inherently a decentralised system, centralisation of all forms of information exchange and various forms of censorship - state or self-imposed - still occurs. In response to the <cite>Telecommunications Act of 1996</cite>, John Perry Barlow voiced a fundamental societal concern in <cite><a data-versiondate="2018-08-28T22:03:12Z" data-versionurl="https://web.archive.org/web/20180828220312/https://www.eff.org/cyberspace-independence" href="https://www.eff.org/cyberspace-independence">A Declaration of the Independence of Cyberspace</a></cite> given the attempts of the <q>governments of the industrial world</q> to exert control over it, the builders of the cyberspace; a self-sovereign online society that is cross- border, culture, with diverse economies is ultimately an opposing force.</p>

              <p id="information-control">Over the years, large-scale centralised systems were built to collect, organise and share data in diverse sectors. The domination of centralisation is essentially due to economic and state incentives, and it has shaped the technical infrastructure: it is currently much easier and more efficient to author, manage, publish, read, and search large amounts of content using centralised platforms. As such the convenience that comes with centralisation is at the user's expense where ownership and access control is compromised, and as a result the user's privacy and security. Moreover, from the service provider's perspective, there is no particular incentive to build interoperable systems as that would entail losing control over data. Since such services hinder information flow; information in one service is not necessarily usable by other applications and services and vice versa, they effectively form information silos - <cite><a data-versiondate="2018-08-30T09:41:26Z" data-versionurl="https://web.archive.org/web/20180830094126/http://dig.csail.mit.edu/2008/Papers/MSNWS/index.html" href="dig.csail.mit.edu/2008/Papers/MSNWS/index.html">Decentralization: The Future of Online Social Networking</a></cite>, 2008.</p>

              <p>In addition to state controlled network infrastructures, information empires like Google, Facebook, Amazon, Elsevier, as well as a long tail of (social media) services, exert a great deal of influence on how information can be accessed, expressed and reused. This influence impacts society, affecting the cost of accessing information, the effort required to produce and distribute, long-standing privacy concerns (in exchange of some convenience for users), as well as how and the amount of information that is aggregated, shared and filtered.</p>

              <p>Independence from centralised platforms is a necessity for ownership of published ideas, and to establish authenticity and trust. For example, Facebook has been accused of <a href="http://www.slate.com/articles/technology/technology/2016/05/yes_facebook_is_biased_now_it_should_admit_it.html">bias</a>, <a href="https://www.theguardian.com/media/2016/jul/12/how-technology-disrupted-the-truth">false information</a>, and <a href="https://www.nytimes.com/2016/09/10/technology/facebook-vietnam-war-photo-nudity.html">censorship</a>â€”but rather than blaming this on any particular platform, we identify it as an unavoidable result of centralisation. After all, there is a continued tension between unrestricted publication rights on the one hand, and a guarantee of balanced, verified information on the other. In a fully decentralised setting, each source is filterless and responsible for its own quality and reputation, while consumers are free to selectively (dis-)trust certain sources using any mechanism they desire, for example through a trusted party or service. For instance, search engines like Google or <cite><a href="https://duckduckgo.com/">DuckDuckGo</a></cite> apply different filtering algorithms based on their Web crawls. Whether consciously or not, why we use a particular search engine naturally correlates with the amount of use or trust we have on that system. Similarly, as the academic peer-review system acts as a layer to regulate credibility of academic contributions, we can approach the research results provided that there is sufficient provenance, accountability of the review process, and able to distinguish different levels of certification given or lack of from the scholarly community.</p>

              <p id="knowledge-commons">The information needs of individuals, communities and societies vary on personal, local and global levels. In <cite><a href="http://www.worldcat.org/oclc/731904330">Understanding Knowledge as a Commons</a></cite>, 2011, Charlotte Hess and Elinor Ostrom, and contributing authors state that scientific communities can make their discoveries and digital resources available to all which can be shared without having a subtractable characteristic like that of print. Through electronic knowledge representations, researchers can take part in reproducing and replicating others' findings; be involved in quality-control and certification processes, as well as incorporate interactions among researchers, examiners, journalists, policy makers, and the general public. Given access to the Internet and the Web, academic researchers can register their URIs, and control how they express their ideas and what they refer to, establish data storage and choose which applications to use for their social and scholarly activity.</p>

              <hr />

              <p>So far we have used the term <q>decentralisation</q> liberally, but in fact it can mean different things depending on the context, community, and collection of standards and technologies that are used. From here on end, we work with the the following definition in context of the Web architecture:</p>

              <blockquote cite="https://content.sciendo.com/downloadpdf/journals/popets/2017/4/article-p404.pdf">
                <dl>
                  <dt>Decentralized system</dt>
                  <dd>A distributed system in which multiple authorities control different components and no single authority is fully trusted by all others.</dd>
                </dl>

                <footer><cite><a data-versiondate="2018-08-27T14:56:53Z" data-versionurl="https://web.archive.org/web/20180827145653/https://content.sciendo.com/downloadpdf/journals/popets/2017/4/article-p404.pdf" href="https://content.sciendo.com/downloadpdf/journals/popets/2017/4/article-p404.pdf">Systematizing Decentralization and Privacy: Lessons from 15 Years of Research and Deployments</a></cite>, 2017, Carmela Troncoso et al</footer>
              </blockquote>

              <p>On the other hand, messages and operations in centralised or distributed systems <q>may be managed by a single root of trust or authority</q>. From this position <q>decentralized systems are a subset of distributed systems</q> where they <q>embody a complex set of relationships of trust between parties managing different aspects of the system</q>. These systems are conceived of as a graph where the nodes correspond to the components of the system, and the edges correspond to connections between them. From a global perspective, the Web is a decentralised system, however, it can have components which are disjoint from the rest of the graph.</p>

              <p>Troncoso et al, consider <em>security</em> and <em>privacy</em> to be integral aspects of systems. Security includes <q>confidentiality, integrity, authentication..availability, accountability, authorization, non-repudiation or non-equivocation</q>, and privacy considers <q>protections of usersâ€™ related data (identities, actions, etc.)</q>, and <q>formalized in terms of privacy properties (anonymity, pseudonymity, unlinkability, unobservability).</q></p>


              <hr />

              <p>How do we "control ourselves" on the modern, overly-centralised Web? Let us now turn our attention to the technicalities of this matter given the possibilities that the Web offers, and the feasibility of using certain Web standards and technologies to address certain kinds of challenges in scholarly communication. We focus on two areas of centralisation that are at the forefront of the way (scholarly) communication is conducted on the Web and its ramifications on the rest of the sociotechnical system:</p>

              <dl id="data-applications">
                <dt>data</dt>
                <dd>information that can be used with intended semantics</dd>
                <dt>applications</dt>
                <dd>computer software that performs functions on data on behalf of a user</dd>
              </dl>

              <p>We focus on interactions based on the client-server model under the <a href="scholarly-communication-on-the-web#architecture-of-the-web">architecture of the Web</a>, where data and applications are conceptually and operationally decoupled units.</p>

              <p>While centralisation of data and applications are two distinct areas of concern, some of the challenges we face in scholarly communication make them appear as one. When we discuss challenges around access to knowledge, the location and quality of the data is often conflated with the tools or services which are required to access the data. Being required to use particular software to create, format or share research articles, to create accounts on particular services, or agree to certain terms and conditions impose a set of characteristics on research output or data itself.</p>

              <p>Data and application appear to be intertwined because the workflows that the researchers are required to use tend to be unique and proprietary and predominantly enforced by third-parties. While some of the differences in designs may be due to historical reasons they also ensure various forms of vendor lock-in on both the research outputs and the applications to generate, share and reuse data. The use of non-interoperable (or even post-facto) methods to create and exchange data on the Web leads to the fragmentation of data through silo-services, and along with it the dependency on applications having their interaction mechanisms established via out-of-band knowledge. If we strictly focus on the current quality of machine-readable scholarly information on the Web, the technical obstacles are evident and ample. The applications need to be continuously hard-wired to know what to look for; what to do once something of interest is found; or where to go next in the discovery phase. Similarly, automating discovery of fine-grained information without human interference is still central to the limitations.</p>

              <hr />

              <p id="from-databases-to-dataspaces">In <cite><a data-versiondate="2018-09-06T13:10:33Z" data-versionurl="https://web.archive.org/web/20180906131033/https://people.eecs.berkeley.edu/~franklin/Papers/dataspaceSR.pdf" href="https://people.eecs.berkeley.edu/~franklin/Papers/dataspaceSR.pdf">From Databases to Dataspaces: A New Abstraction for Information Management</a></cite>, 2005, Franklin et al, raises a challenge of organisations <q>relying on large number of diverse, interrelated data sources, but having no way to manage their <em>dataspaces</em> in a convenient, or principles fashion.</q>. The article brings forth the notion of dataspaces as a <q>data co-existence</q> approach, with the goal of providing functionality over all data source. In such systems, there is a set of participants and relationships, while remaining sensitive to their requirements of autonomy. The authors propose the development of different <q>DataSpace Support Platform</q>s (<abbr title="DataSpace Support Platform">DSSP</abbr>) where interrelated services would allow data to be managed by participant systems.</p>

              <p id="principles-of-dataspace-systems">In <cite><a data-versiondate="2018-09-06T15:03:00Z" data-versionurl="https://web.archive.org/web/20180906150300/https://homes.cs.washington.edu/~alon/files/pods06.pdf" href="https://homes.cs.washington.edu/~alon/files/pods06.pdf">Principles of Dataspace Systems</a></cite>, 2006, Halevy et al, explores challenges that are involved in realizing DSSPs based on motivating applications eg. personal information management (<abbr title="Personal Information Management">PIM</abbr>), scientific data management, structured queries and content on the Web. Authors conclude that <q>interoperability and interchangeability of multiple components is key to the success of DSSPs.</q></p>

              <p id="paygo">In <cite><a data-versiondate="2018-09-06T09:36:45Z" data-versionurl="https://web.archive.org/web/20180906093645/http://cidrdb.org/cidr2007/papers/cidr07p40.pdf" href="http://cidrdb.org/cidr2007/papers/cidr07p40.pdf">Web-scale Data Integration: You can only afford to Pay As You Go</a></cite>, 2007, Madhavan et al, propose the notion of a <abbr title="Pay as you go">PAYGO</abbr> data integration architecture with the premise that it is impossible to fully integrate vast heterogeneous collections of structured data that exists on the Web. The PAYGO principle states that a system needs to be able to incrementally evolve in its understanding of underlying data's structure, semantics, and relationships between sources.</p>

              <p id="distributed-semantic-social-networks">In <cite><a href="http://svn.aksw.org/papers/2011/SWJ_DSSN/public.pdf">An Architecture of a Distributed Semantic Social Network</a></cite>, 2012, and <cite><a href="http://ul.qucosa.de/api/qucosa%3A12983/attachment/ATT-0/">Distributed Semantic Social Networks: Architecture, Protocols and Applications</a></cite>, 2014, Sebastian Tramp posits that the landscape of Social Web is increasingly losing its distributed nature. Tramp highlights that there is an increased use of centralised social platforms, where users are locked in to their respective platforms with not much opportunity to communicate easily with users on other platforms, as well as difficulty to relocate their social graphs and personal data. Interoperability between platforms being largely limited to proprietary APIs, and changes being at the discretion of the service provider. Users of the online services are being required to keep their - often overlapping - data individually at each platform up to date in order to minimise divergent information. Tramp argues that technical solutions should empower users to regain control and ownership over their data and its use, ensure privacy policies and rules that's user-centric (as opposed to driven by commercial interest), increased data security, information extensibility based on user's needs, reliability through distribution, and freedom of communication without centralised control. The output of Tramp's research is that Semantic Web technologies can be deployed to some extant to support the structure, maintenance, and usage of federated and distributed social networking on the Web. The evaluation is based on integration use case tests, eg. <cite><a href="https://www.w3.org/2005/Incubator/federatedsocialweb/wiki/SWAT0">SWAT0</a></cite>, <cite><a href="https://www.w3.org/2005/Incubator/federatedsocialweb/wiki/SWAT1_use_cases">SWAT1</a></cite>, formulated by the W3C <cite><a href="https://www.w3.org/2005/Incubator/federatedsocialweb/">Federated Social Web Incubator Group</a></cite>.</p>

              <p id="data-ownership-and-interoperability-for-a-decentralized-social-semantic-web">In <cite><a href="https://tel.archives-ouvertes.fr/tel-00917965/document">Data ownership and interoperability for a decentralized social semantic web</a></cite>, 2013, Andrei Vlad Sambra acknowledges the same core challenges of the modern Web as Tramp, and sets out to identify key components that would help achieve true data ownership and interoperability. Sambra demonstrates how a stack of interoperable Web technologies around WebID and Linked Data can be used to build certain class of social Web applications, where users without centralised intermediaries can authenticate themselves, and participate in creating and exchanging data with servers that are equipped with social access controls.</p>

              <p id="amber-decoupling-user-data-from-web-applications">In <cite><a href="https://pdos.lcs.mit.edu/papers/amber:hotos15.pdf">Amber: Decoupling User Data from Web Applications</a></cite>, Chajed et al, 2015, posit that <q>users control their own data</q> choosing which applications to manipulate their data as well as their ability to share data between applications and with other users. <cite>Amber</cite> is a proposed architecture that looks into overcoming challenges on inexpensive querying, an expressive authentication and access control system, users trusting their platform, being able to handle large volumes of data and query results, offline capabilities, and a sensible economic compatibility among its users, platform, and application developers. The results from Amber show that the architecture is most useful when data is associated with users, and operations on the data are carried out in Web browsers.</p>

              <p id="a-demonstration-of-the-solid-platform-for-social-web-applications">In <cite><a data-originalurl="https://doi.org/10.1145/2872518.2890529" data-versiondate="2018-08-21T10:11:43Z" data-versionurl="https://web.archive.org/web/20180821100927/http://gdac.uqam.ca/WWW2016-Proceedings/companion/p223.pdf" href="http://gdac.uqam.ca/WWW2016-Proceedings/companion/p223.pdf">A Demonstration of the Solid Platform for Social Web Applications</a></cite>, 2016, Essam Mansour et al raise the concern that well-known Social Web applications are essentially <q>data silos</q> involving design patterns where each application is custom built to store its own data, along with custom authentication and access control mechanisms. Hence, users of such systems often cannot easily switch personal data storage services, or reuse their data with similar applications. Authors demonstrate the <cite>Solid platform</cite> to address the challenges in decentralised authentication, data management, as well as the development of interoperable and portable Social Web applications that interact with the platform. A number of servers and client applications are implemented where it is possible to store RDF and non-RDF resources, as well as permitting operations via SPARQL queries for complex data retrieval and link-following. The client-side applications cover common "day-to-day" tasks eg. contacts management, event organisation, collaborative authoring, annotating, and social notifications, all meanwhile users are able to use their WebIDs and switch between applications with similar functions.</p>
            </div>
          </section>

          <section id="read-write-linked-data" inlist="" rel="schema:hasPart" resource="#read-write-linked-data">
            <h2 property="schema:name">Read-Write Linked Data</h2>
            <div datatype="rdf:HTML" property="schema:description">
              <p>Both Tramp and Sambra emphasise on using and extending the Web architecture and applying its principles towards a more decentralised notion of information reuse and user interaction. The core approaches use the Linked Data technology stack for publishing, retrieval, and integration; decoupling services and applications from the users data so that content creators are owners and have desired rights on their data and its use; and fostering data extensibility and distribution, as well as privacy.</p>

              <p id="internet-web-protocols">The foundational communication and transfer protocols of the Internet and the Web are designed to operate in a decentralised and distributed manner. In terms of global functionality, removing a single node from the network - a machine with an IP address - does not halt the whole network. Similarly, when an HTTP URL is no longer available (eg. typical "404 Not Found", "410 Gone" status messages), the other URLs are not affected. This particular behaviour, where the Web being functional without requiring bi-directional hyperlinks is considered to be a "feature" (rather than a "bug") of the overall system.</p>

              <p id="read-write-web">As discussed previously the <abbr title="Architecture of the World Wide Web">AWWW</abbr> enables the identification, discovery and description of information for the notion of a <q>Read-Write Web</q> where servers and clients interact using Web standards. Generally speaking <cite><a href="https://en.wikipedia.org/wiki/Create,_read,_update_and_delete">create, read, update and delete</a></cite> (<abbr title="Create, Read, Update and Delete">CRUD</abbr>) are the basic functions of persistent storage as well as conventions for user-interfaces to view and change information. Each CRUD operation can be mapped to an interaction method of the Web architecture. For example, the request function for HTTP would be: <math alttext="upper R e q u e s t equals upper M e t h o d vector-or-cross-product upper I upper R upper I vector-or-cross-product upper M e d i a upper T y p e vector-or-cross-product upper B o d y" xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>Request</mi><mo>=</mo><mi>Method</mi><mo>â¨¯</mo><mi>IRI</mi><mo>â¨¯</mo><mi>MediaType</mi><mo>â¨¯</mo><mi>Body</mi></mrow></math>, where <em>IRI</em> being the identifier of a resource, and <em>MediaType</em> indicating the format of the content in <em>Body</em>, the mapping to some HTTP method(s) <em>typically</em> used as follows (implementations may differ in some areas):</p>

              <ul>
                <li><em>create</em>: <code>PATCH</code>, <code>POST</code>, <code>PUT</code>;</li>
                <li><em>read</em> (retrieve): <code>GET</code>. <code>HEAD</code>, <code>OPTIONS</code>;</li>
                <li><em>update</em> (modify): <code>PATCH</code>, <code>POST</code>, <code>PUT</code>;</li>
                <li><em>delete</em> (destroy): <code>DELETE</code>, <code>PATCH</code>.</li>
              </ul>

              <p id="socially-aware-read-write-linked-data">In <cite><a href="https://www.w3.org/DesignIssues/CloudStorage">Socially Aware Cloud Storage</a></cite> and <cite><a href="https://www.w3.org/DesignIssues/ReadWriteLinkedData">Read-Write Linked Data</a></cite>, Berners-Lee discusses where the Web architecture together with existing or future communication protocols and data standards can be used to materialise a <q>socially-aware decentralized access control of reading and of writing to linked data, and of notification of changes.</q> The overarching goal is to enable people and software to co-create information, and as well as to interact with information using social applications. This is all meanwhile technically and legally enabling participants to retain their autonomy, identity and storage, access and rights over their contributions. In order to achieve this, one of the goals is to make and an infrastructure where data and applications are decoupled by design. That is, an ability to work with linked data without constraints on which applications can be used, as long as they follow consensus-based open protocols and data models. At the core of this initiative is where users, groups, and applications use global identifiers (URIs), and  access control is applied using policies assigned to those identifiers. This also leads to the commodification of read-write data storage; the storage location on the Web can be decided by its owners and contributors, and it remains independent from the applications interacting with it.</p>

              <hr />

              <p>The following are a selection of open Web specifications; standards and practices that are designed with the notion of decentralisation, interoperability, and extensibility. They are based on use cases that facilitate discovery, read-write operations of interlinked Web resources. Their core functions are listed in context of the forces in scientific communication in Table [<a href="#specifications-for-forces-and-functions">specifications-for-forces-and-functions</a>].</p>

              <p id="linked-data-platform"><cite><a href="https://www.w3.org/TR/ldp/">Linked Data Platform</a></cite> (<abbr title="Linked Data Platform">LDP</abbr>) specifies a <q>RESTful</q> read-write protocol and vocabulary for Web resources. LDP has distinct notions for <q>resource</q> and <q>container</q>; where the container construct can group and manage resources. LDP uses the RDF data model to describe the state of RDF and non-RDF resources. <cite><a href="https://www.w3.org/TR/ldp-ucr/">Linked Data Platform Use Cases and Requirements</a></cite> outlines a wide-range of user stories, use cases, scenarios, and requirements which was used as the bases for the LDP specification. LDP can be used to mimic a file system abstraction interacting with Web resources over HTTP. The <cite><a href="https://www.w3.org/TR/ldp-paging/">LDP Paging</a></cite> mechanism can be used by clients and servers to efficiently request and serve a resource description, eg. resources in a container, in multiple parts. All LDP servers and clients can interact with each other using the same HTTP interface in context of Linked Data to perform CRUD operations. An LDP server can facilitate researchers to register and store their resources, as well as share their structured and unstructured content by applying different access controls. Users and applications can discover information and perform CRUD operations using the Web interface.</p>

              <p id="hydra-core-vocabulary"><cite><a href="http://www.hydra-cg.com/spec/latest/core/">Hydra</a></cite> is a vocabulary to enable the creation of hypermedia-driven Web APIs by enabling a server to advertise affordances of its resources - machine-readable valid state transitions - to a client. A client uses this information to construct HTTP requests in order to perform possible read-write operations. Hydra enables generic client applications to be built without hardcoding knowledge about the available operations against Web APIs. With Hydra, applications can automate some of their tasks and only request researchers' engagement when need to.</p>

              <p id="linked-data-fragments"><cite><a href="http://linkeddatafragments.org/">Linked Data Fragments</a></cite> (<abbr title="Linked Data Fragments">LDF</abbr>) is the concept of having a uniform view on Linked Data interfaces that can be used towards reliable Web querying. To that end, a client asks a server about the kinds of Linked Data fragments that are available and then dynamically adapts its query plan for the server to execute. A Linked Data fragment is defined by three characteristics: data (what triples does it contain?), metadata (what do we know abut it?), controls (how to access more data?). LDF-based interactions can help researchers to inspect available scientific data through their distinct characteristics.</p>

              <p id="triple-pattern-fragments"><cite><a href="http://www.hydra-cg.com/spec/latest/triple-pattern-fragments/">Triple Pattern Fragments</a></cite> (<abbr title="Triple Pattern Fragments">TPF</abbr>) is one possible way for a server to define a Linked Data fragment that enable live querying over the dataset on the client-side. TPF's hypermedia controls are expressed using the Hydra vocabulary.</p>

              <p id="linked-data-templates"><cite><a href="https://atomgraph.github.io/Linked-Data-Templates/">Linked Data Templates</a></cite> (<abbr title="Linked Data Templates">LDT</abbr>) provides the means to define read-write Linked Data APIs declaratively using SPARQL and specify a uniform interaction protocol for them. An LDT based server applies re-usable RDF ontologies to define application structure declaratively as a set of instructions for resource representation processing. To this end, "templating" is where an HTTP operation is mapped to a certain URI pattern that a server executes a SPARQL command in order to drive RDF CRUD processing. When a client triggers a particular request pattern, the server gives a suitable response based on available templates that are identified with URIs. LDT allows arbitrary academic and research applications to be built while exposing a uniform API that can be used in decentralised environments.</p>

              <p id="rdf-post"><cite><a href="http://www.lsrn.org/semweb/rdfpost.html">RDF/POST Encoding for RDF</a></cite> uses the W3C HTML 4.01 Recommendation to specify read-write operations of RDF data through form-encoded RDF serialisation. Read operations are done by having an RDF/POST document encoded in HTTP GET URL, and write operations are sent via HTTP POST with form-urlencoded media type. CRUD operations that are generally equivalent to LDP or LDT can be achieved with RDF/POST.</p>

              <p id="fedora-api"><cite><a href="https://fcrepo.github.io/fcrepo-specification/">Fedora API Specification</a></cite> refines the semantics and interaction patterns of the LDP specification in order to address the needs of repositories for durable access to digital data. Its goal is to facilitate interoperability with client applications. While the interactions patterns provides a mechanism for different client applications to communicate with servers, servers can be expected to vary in the kinds of services and affordances they offer for their resources. Fedora uses LDP as a foundation and defines the version identification and navigation scheme with respect to the <a href="#memento">Memento specification</a>, integrates resource authorization and <a href="#acl">access control list</a> rules (both described below), provides a design for the publication of event notifications, and interaction patterns to support binary resource fixity verification. The Fedora API can fulfil the registration, awareness and archiving functions, while enabling different actors to cooperate across instances on each others resources through independently built applications.</p>

              <p id="memento"><cite><a href="https://tools.ietf.org/html/rfc7089">HTTP Framework for Time-Based Access to Resource States -- Memento</a></cite> (<abbr title="HTTP Framework for Time-Based Access to Resource States -- Memento">Memento</abbr>): introduces a uniform, datetime-based, version access capability that integrates present and past Web resources. As representations of resources change over time, there is a need to preserve (archive and version) earlier representations. One common resource versioning pattern on the Web consists of generic URIs referring to the latest version of an accessible resource, as well as having a dedicated version URI for each resource. The Memento framework facilitates the discovery and retrieval of distributed versioned resources with datetime negotiation, a variant of content-negotiation; and TimeMaps an index of URIs referring to the prior states of a resource. The framework also helps to recognise frozen states of resources - a promise that the resource state has not and will not change. The Memento protocol can assist scientific applications to discover and reveal the variations of scholarly artifacts.</p>

              <p id="web-annotation"><cite><a href="https://www.w3.org/annotation/">Web Annotation</a></cite> (<abbr title="Web Annotation">WA</abbr>) is set of specifications for an interoperable, sharable, distributed Web Annotation architecture. The annotations convey information about a resource or associations between resources to meet different motivations and purposes, eg. assessing, replying, describing, bookmarking, as well as <q cite="https://www.w3.org/TR/annotation-model/#abstract">linking arbitrary content to a particular data point or to segments of timed multimedia resources</q>. <cite><a href="http://www.w3.org/TR/annotation-protocol/">Web Annotation Protocol</a></cite> is the HTTP API for publishing, syndicating, and distributing Web Annotations. Much of the protocol is based on using and extending LDP and REST best practices. <cite><a href="http://www.w3.org/TR/annotation-model/">Web Annotation Data Model</a></cite> describes the underlying annotation <em>abstract</em> data model as well as a JSON-LD serialization. The WA Protocol uses an LDP container to manage annotations with some constraints derived from the WA Model. Scholars can use servers and applications that support Web Annotation in order to annotate scholarly literature to meet the certification function.</p>

              <p id="activity-streams"><cite><a href="https://www.w3.org/TR/activitystreams-core/">Activity Streams 2.0</a></cite> (<abbr title="Activity Streams 2.0">AS</abbr>) detail a model for representing potential and completed activities with the intention of using specific types of activity vocabularies defined elsewhere. The <cite><a href="https://www.w3.org/TR/activitystreams-vocabulary/">Activity Vocabulary</a></cite> provides a foundational vocabulary to describe past, present, and future activities eg. announcing, creating, following, offering, and about objects eg. actors, media. Various academic and research activities can be recorded and brought to the attention of actors to determine their applicability and allow management of scholarly knowledge.</p>

              <p id="linked-data-notifications"><cite><a href="https://www.w3.org/TR/ldn/">Linked Data Notifications</a></cite> (<abbr title="Linked Data Notifications">LDN</abbr>) is a resource-centric communication protocol for applications to generate notifications about activities, interactions, and new information, which may be presented to the user or processed further. It allows any resource (target) to advertise a receiving endpoint (inbox) for the messages anywhere on the Web. The server (receiver) hosting the inbox can have messages pushed to them by applications (sender), as well as how other applications (consumer) may retrieve those messages. Each notification in an inbox is an identifiable and reusable unit (URI), and can contain any data using any vocabulary. LDN can be combined with Web Annotation and Activity Streams to support applications to deliver and consume notifications about research and scholarly activities. We revisit LDN and discuss its role in research communication where it supports the accessibility, content forces, and how it can perform the registration and awareness functions in its own <a href="linked-data-notifications">section</a>.</p>

              <p id="activitypub"><cite><a href="https://www.w3.org/TR/activitypub/">ActivityPub</a></cite> (<abbr title="ActivityPub">AP</abbr>) is a decentralized social networking protocol based upon the Activity Streams 2.0 data format. It provides a client to server API for CRUD operations, as well as a federated server to server API for delivering notifications and content. User accounts on servers have an inbox (to receive messages from the world), and an outbox (to send messages to others). AP's inbox property is the same as LDN's, and the targeting and delivery mechanism can be interoperably combined. AP can facilitate distributed scholarly interactions by allowing actors to disseminate their operations on their own, as well as others' data. It serves to fulfil various social scholarly Web functions.</p>


              <p id="read-write-linked-data-design-pattern">The design pattern for these read-write Linked Data centric protocols and architectures can be categorised as follows:</p>

              <ul>
                <li>the ability to perform CRUD interactions against Web resources</li>
                <li>decoupling software from domain or application-specific operations and data</li>
                <li>descriptive, extensible, and interconnected units of information</li>
                <li>declarative and machine-readable affordances for valid read-write operations</li>
              </ul>
            </div>
          </section>


          <section id="universal-identity-for-the-web" inlist="" rel="schema:hasPart" resource="#universal-identity-for-the-web">
            <h2 property="schema:name">Universal Identity for the Web</h2>
            <div datatype="rdf:HTML" property="schema:description">
              <p>One of the functions of an online identity is to a identify a persisting entity at a particular time and context. The construction of an online identity of an entity eg. individual, organisation, community, state, can be complex in that it is interconnected with social and technical systems, and it can be issued - declared to exist, named, or be referenceable - in different ways.</p>

              <p id="social-personal-data-stores">In <cite><a href="https://www.research.ed.ac.uk/portal/files/20028374/vanKleek_et_al_2015_Social_Personal_Data_Stores.pdf" title="https://doi.org/10.1145/2740908.2743975">Social Personal Data Stores: the Nuclei of Decentralised Social Machines</a></cite>, 2015, Max Van Kleek et al, considers decentralised social applications from the user's perspective based on the shortcomings and dangers of <span lang="la" title="Latin phrase refering to what happens in practice, in contast to law" xml:lang="la">de facto</span> practices where user data and interactions being controlled by centralised service providers. The work states that existing personal data stores for the most part do not <q>account for the need for multiple identities, effective separation of roles and anonymity, and to prevent unwanted tracking and clickstream profiling</q>, and that future work should integrate people's need for privacy, creation, management, and switching of separate identities, pseudonyms, personas in order to be used in different contexts, eg. personal, professional.</p>

              <p id="the-presentation-of-self-on-a-decentralised-web">In <cite><a href="http://dr.amy.gy/">The Presentation of Self on a Decentralised Web</a></cite>, 2017, Amy Guy, the <q cite="https://rhiaro.github.io/thesis/chapter3#what-is-a-profile">What is a profile?</q> study describes <q>affordances of systems which integrate online profiles in a social capacity and raises five features of systems with regards to their representations of users: flexibility, access control, prominence, portability, representation.</q> Furthermore, Guy posits that <q cite="https://rhiaro.github.io/thesis/chapter3#ccccc">online self-presentation is both constituted and affected by <em>who</em> sees a representation of an individual, and <em>what</em> it is they see, both of which are encompassed by the situation <em>whereby</em> it is seen</q>. The results of the studies are summarised as a conceptual framework as the <q id="ccccc">5Cs</q> for online profiles and self presentation: <q>context, control, customisability, connectivity, cascade</q>.</p>

              <p id="third-party-controlled-identity"><strong>Third-party controlled identity</strong>: Community or state controlled identifiers for identities are a class of identifiers that are ultimately third-party controlled in that their ownership, governance, description is beyond an individual's jurisdiction. The creation and control of identifiers by a group has the quality of long-term promise for persistence. Typically there are policies in place which promise their longevity, and procedures in the event that the group longer ceases to manage the identifiers. For example, ORCID URIs are intended to be part of the scholarly commons where they managed by the <a href="https://orcid.org/about/community">community</a>. As discussed earlier, ORCID URI and profile description is useful to researchers, organisations, as well as to interlink researcher objects, however it is ultimately intended to serve the research community, and the systems that use it. One unintended consequence of this kind of centralisation in scholarly communication is that a growing number of institutions and publishers require researchers to participate with their ORCID identifiers, as opposed to any URI of a researcher. The resulting effects of <a href="https://orcid.org/content/requiring-orcid-publication-workflows-open-letter">such initiatives</a> are counter to autonomous participation in that a researcher has to conform to the terms and policies of multiple third-parties. On the other hand, the administration of the URI by the ORCID organisation removes the burden of maintaining the URI as well as the profile URL. In this case, a "trusted" third-party takes care of the identifier, whereas researchers are responsible of updating the content.</p>

              <p id="self-controlled-identity"><strong>Self-controlled identity</strong>: The concept of a personal self-sovereign identity entails that entities can register and manage their own identities in a location of their choice.</p>

              <p id="identity-http-uri">Different types of strings, eg. a username, an email address, an RSA public key, a URI, can be used to directly or indirectly identify agents. While each can be useful within their own context, Web-based identifiers (HTTP URI) make it possible to provide machine-readable descriptions when dereferenced, descriptions being extensible by their owners, as well as being interoperable global identifiers that can be interlinked unambiguously with other things.</p>

              <p id="identity-privacy-spectrum"><q cite="https://www.w3.org/TR/verifiable-claims-data-model/">Privacy is a spectrum that ranges from pseudo-anonymous to fully identified.</q> For example, a server can collect information about a client based on its device, machine, or browser fingerprint, even if the user did not directly disclose information about themselves. On the other hand, global identifiers like government-issued identifiers, credit card numbers, and full names, can be used to determine, track, and correlate an entity.</p>

              <p id="future-of-social-networking">The <cite><a href="https://www.w3.org/2008/09/msnws/report.html">W3C Workshop on the Future of Social Networking Report</a></cite>, 2009, concluded that distributed social networking is a possibility on the Web, given available data interoperability technologies, as well as further support of open source implementation of decentralised architectures. At the crux of the initiatives was to: foster preservation of privacy best practices for users; and their ability to trust claims; deepening user contexts and roles in social networking; enabling protocols for exchanging goods and services within communities, and; creating adapted user experienced with improved accessibility and mobility by closing the gap between implementations of social networks and device capabilities.</p>

              <p id="foaf+ssl">One of the conclusions of the workshop was that many of the existing technologies needed to create decentralized social networks already existed, eg. FOAF, OpenID, XMPP. <a href="https://www.w3.org/2008/09/msnws/papers/foaf+ssl.html" title="FOAF &amp; SSL: creating a global decentralised authentication protocol">One of contributions to the workshop</a> was presented by Henry Story et al based on <a href="https://web.archive.org/web/20080426014047/http://blogs.sun.com:80/bblfish/entry/foaf_ssl_creating_a_global is">original proposal</a> (combining <cite><a href="https://web.archive.org/web/20080426142811/http://blogs.sun.com:80/bblfish/entry/rdfauth_sketch_of_a_buzzword">RDFAuth</a></cite> by Henry Story and <cite><a href="https://lists.w3.org/Archives/Public/semantic-web/2008Mar/0207.html">sketch of a simple authentication protocol</a></cite> by Toby Inkster in 2008) for the notion of using Semantic Web vocabularies such as <abbr title="Friend of a Friend">FOAF</abbr> with SSL certificate exchange mechanism permits distributed and interlinked social networks to exist. The protocol was later posited in <cite><a href="http://dig.csail.mit.edu/2009/Papers/SPOT/foaf-ssl-spot2009.pdf">FOAF+SSL: RESTful Authentication for the Social Web</a></cite>. Its goal was set to protecting and controlling access to personal information distributed on the Web where identification and privacy is at its centre. The work on WebID and related extensions described below builds on this work.</p>

              <p id="webid-specs">In order to enable people, group and software to act as autonomous agents that can cooperate on the Web, we need methods for distributed and decentralised identity, secure authentication, and access control. <cite><a href="https://www.w3.org/2005/Incubator/webid/spec/">WebID</a></cite> is a group of specifications that outlines approaches meet those needs.</p>

              <p id="webid"><cite class="highlight-webid"><a href="https://www.w3.org/2005/Incubator/webid/spec/identity">Web Identity and Discovery</a></cite> (<abbr title="Web Identity and Discovery">WebID</abbr>) is a specification that outlines a distributed and extensible universal identification mechanism on the Web. A WebID is an HTTP URI denoting an agent, for example a person, organisation, or software. It can be used towards the declaration of an agent's existence; discovery, describing or reference; authentication; and authorisation. WebID is distributed and decentralised in that any agent can be <em>named</em> anywhere on the Web, and the server hosting the URI space controls the identity. It is extensible in that it can be used injunction with secure authentication and access control mechanism, as well as having dereferenceable machine-readable descriptions which are themselves extensible. WebID can improve privacy, security, and control be in the hands of users. WebID fulfils registration of identities of academics and researchers, helps them to be associated with scholarly artifacts they interact with.</p>

              <p id="webid-profile"><cite class="highlight-webid-profile"><a href="https://www.w3.org/2005/Incubator/webid/spec/identity/#dfn-webid_profile">WebID Profile</a></cite> is an RDF document which uniquely describes agents denoted by a WebID. The profile description is a way for researchers to extend the information about themselves; specify their preferences, the location of their storage, and scholarly artifacts; how they can be contacted; their associations with other researchers, as well as other identities, and so forth. It serves to make identity claims which can be coupled with verification systems.</p>

              <p>The <cite>WebID</cite>: <samp class="highlight-webid">http://csarven.ca/#i</samp> refers to me (in real life) via the description found at the location of the <cite>WebID Profile</cite> document: <a class="highlight-webid-profile" href="http://csarven.ca/">http://csarven.ca/</a>:</p>

              <figure class="listing" id="webid-profile-example">
                <p><a class="highlight-webid" href="http://csarven.ca/#i" title="WebID"><span class="highlight-webid-profile" title="WebID Profile">http://csarven.ca/</span>#i</a></p>

                <style> #webid-profile-example > p { display:inline-block; } #webid-profile-example > p a { border: 3px solid #f00; padding: 0.5em; letter-spacing:3px; text-decoration: none; } #webid-profile-example > p a span { border: 3px dashed #00f; padding: 0.15em; }</style>

                <pre><code>&lt;<span class="highlight-webid-profile">http://csarven.ca/</span>&gt;</code>
<code>  a foaf:PersonalProfileDocument ;</code>
<code>  foaf:primaryTopic &lt;http://csarven.ca/#i&gt; .</code>
<code></code>
<code>&lt;<span class="highlight-webid">http://csarven.ca/#i</span>&gt;</code>
<code>  a foaf:Person ;</code>
<code>  foaf:name "Sarven Capadisli"@en ;</code>
<code>  foaf:mbox &lt;mailto:info@csarven.ca&gt; ;</code>
<code>  foaf:img &lt;http://csarven.ca/media/images/sarven-capadisli.jpg&gt; ;</code>
<code>  foaf:interest &lt;https://en.wikipedia.org/wiki/Media_theory&gt; ;</code>
<code>  cert:key &lt;http://csarven.ca/#cert&gt; ;</code>
<code>  foaf:account &lt;irc://irc.freenode.net/csarven,isnick&gt; ;</code>
<code>  foaf:knows &lt;https://www.w3.org/People/Berners-Lee/card#i&gt; ;</code>
<code>  pim:storage &lt;http://csarven.ca/&gt; ;</code>
<code>  ldp:inbox &lt;http://csarven.ca/inbox/&gt; ;</code>
<code>  as:outbox &lt;http://csarven.ca/outbox/&gt; ;</code>
<code>  foaf:made &lt;https://dokie.li/&gt; ;</code>
<code>  rdfs:seeAlso &lt;http://csarven.ca/cv&gt; .</code></pre>
                <figcaption>An WebID Profile describing a WebID.</figcaption>
              </figure>


              <p id="multiple-identities"><strong>Multiple identities</strong>: Individuals may want to be associated with multiple identities to fulfil diverse needs and social expectations. For instance, academics, politicians, employees, and artists, to name a few, may want to perform their online activities using public identifiers, so that they can be discovered, attributed, rewarded, trusted etc.. There can also be quasi-public identities issued by a government or a  bank to connect individuals to the physical world. Furthermore, individuals may wish to have several personal - public or private - identities and self representations, eg. on social networks. At any event, identities and corresponding identifiers can be registered and managed by different entities, and may be interlinked.</p>

              <p id="orcid-sameas-webid">For instance, while ORCID profile description has constraints, it allows extensibility in the form of asserting a "same as" relation through its UI, so that the ORCID URI can be linked to other WebIDs. This essentially makes a connection to another <a href="structure-of-scholarly-information#self-describing">self-describing document</a> and facilitates <a href="structure-of-scholarly-information#follow-your-nose">follow-your-nose</a> discovery. My personal WebID which is under my control is <a href="http://csarven.ca/#i">http://csarven.ca/#i</a>. I also have an ORCID identifier that also serves as a WebID: <a href="https://orcid.org/0000-0002-0880-9125">https://orcid.org/0000-0002-0880-9125</a> which also has an RDF representation. As ORCID's user interface allows people to extend their descriptions with certain fields, it is possible to add <em>same as</em> or <em>preferred URI</em> relations:</p>

              <figure class="listing">
                <pre><code>&lt;https://orcid.org/0000-0002-0880-9125&gt; ;</code>
<code>  <span class="highlight-predicate-sameas">owl:sameAs</span> &lt;http://csarven.ca/#i&gt; ;</code>
<code>  contact:preferredURI "http://csarven.ca/#i" .</code></pre>
                <figcaption>WebID with same as and preferred URI relations.</figcaption>
              </figure>

              <p>The <code class="highlight-predicate-sameas">owl:sameAs</code> and <code>contact:preferredURI</code> information provides an opportunity for applications consuming the ORCID WebID to potentially discover more information about other entities. This is particularly useful as the ORCID WebID Profile is not completely open to add arbitrary information. For example, specifying a person's picture or their contacts is not currently possible with ORCID, however, if the alternative profiles (http://csarven.ca/#i) contain such information, they can be purposed to know more about the entity.</p>
            </div>
          </section>

          <section id="authentication-and-authorization" inlist="" rel="schema:hasPart" resource="#authentication-and-authorization">
            <h2 property="schema:name">Authentication and Authorization</h2>
            <div datatype="rdf:HTML" property="schema:description">
              <p id="trust">Trust is ultimately tied to verifiable claims about identity and their provenance. While the creation and protection of third-party controlled online identities have received much focus, claiming and using personal identities online is still a challenge. Today's Web applications predominantly make use of online identities that are essentially tied to and controlled by authorities in which users are merely borrowing an identifier and its management. It is a common practice to where users are required to create accounts at each online service they wish to use, eg. social media sites. Moreover, the trust model of such design dictates claims and usage of online identities is not ultimately in the hands of the users, and can be taken away from the users by the owners of the URIs and service at any time and reason. Even in cases where third-party issues identities can be used across different services, it is subject to a privacy violation as the identity provider essentially gets to know which services the user's online identity is used with and for what purpose. Consequently such services can gradually build up information about users' actions as well as behavioural patterns on the Web. Lastly, portability and interoperability of the identities is generally under developed as there is no particular incentive for an identity provider to make it so - after all, providing "free" services for online identities, and then locking identities to well-defined circle of services is taken advantage of by large corporations given their business models. Perhaps most importantly, such online services (as well as applications) do not recognise the identity of users as a distinct notion from the applications and services they use towards authentication.</p>

              <p id="authentication-mechanisms">While there are different authentication mechanisms, here we limit our coverage based on open standards and decoupling of identity, authentication and authorization process, as well as the resource server that the accounts are available from. Hence we categorically omit service-based authentication workflows which are known to require an account name and password, as well as for instance <cite><a href="https://tools.ietf.org/html/rfc7617">The 'Basic' HTTP Authentication Scheme</a></cite>.</p>

<!--
<cite><a href="https://www.w3.org/TR/webauthn/">Web Authentication: An API for accessing Public Key credentials</a></cite>
-->

              <p id="web-of-trust"><cite><a href="https://en.wikipedia.org/wiki/Web_of_trust">Web of Trust</a></cite> (<abbr title="Web of Trust">WoT</abbr>) is a concept for a decentralised trust model used in systems like <cite><a href="https://en.wikipedia.org/wiki/Pretty_Good_Privacy">Pretty Good Privacy</a></cite> (<abbr title="Pretty Good Privacy">PGP</abbr>) to establish the authenticity of the binding between a public key and its owner. A public key cryptographic system uses a pair of keys: public keys (disseminated openly) and private keys (withheld by the owner). It has two main functions: authentication and encryption. For authentication, public key verifies that a holder of the paired private key sent the message. In the case of encryption, for example, when Guinan wants to send Picard a message, Guinan takes Picard's public key to encrypt a message where only Picard can decrypt the message with his private key. WoT essentially leaves trust decisions to the users, as opposed to a centralised authority. Thus, WoT uses self-signed certificates and third-party attestation of those certificates, eg. at <a href="https://en.wikipedia.org/wiki/Key_signing_party">key signing parties</a>. Self-signing certificates removes the dependency on hierarchical certificate authorities to assert identity.</p>

              <p id="x509"><cite><a href="http://www.itu.int/rec/T-REC-X.509/en">X.509</a></cite> is a standard for public key certificates that specifies a structure for a digital certificate, including a public key associated with one or more identities, as well as extensions for new information. X.509 essentially serves as a identity card that can be used to store identity claims. X.509 certificates can be used to authenticate both servers and clients. <cite><a href="https://tools.ietf.org/html/rfc2818">HTTP over TLS</a></cite> (<abbr title="Hypertext Transfer Protocol Secure">HTTPS</abbr>) - an extension of HTTP for secure communication - uses the <cite><a href="https://tools.ietf.org/html/rfc5280">Internet X.509 Public Key Infrastructure Certificate and Certificate Revocation List (CRL) Profile</a></cite>.</p>

              <p id="tls"><cite><a href="https://tools.ietf.org/html/rfc5246">The Transport Layer Security Protocol Version 1.2</a></cite> (<abbr title="Transport Layer Security">TLS</abbr>) is a cryptographic protocol aimed at providing secure connections between applications. When applications eg. a server and a client (Web browser), communicate using the TLS protocol, it is private (secure) in that data is encrypted, identity of either party can be authenticated using public key cryptography (like PGP), and integrity of the exchanged data can be assured during transit.</p>

              <p id="webid-tls"><cite><a href="https://www.w3.org/2005/Incubator/webid/spec/tls">WebID-TLS</a></cite> defines how a server can authenticate a user with a client application holding the user's public key certificate, and serves towards identity claim verification. As the extension mechanism in X.509 allows additional statements to be specified under the <code>Subject Alternative Name</code> (<abbr title="Subject Alternative Name">SAN</abbr>) field, it is used to declare the user's WebID for the <code>URI</code> field. When a client application running on the Web browser requests a resource from the server, the TLS connection gets established between them. Once TLS has been set up, the HTTP application protocol exchange takes place (eg. <code>GET</code>, <code>POST</code>). If the requested resource requires WebID authentication the server can request the client to authenticate itself. When the Web browser encounters this certificate request, it may prompt its user to choose a certificate (from its certificate manager) - thereby signing a token with its private key - to let the client send it to the server. The verification agent extracts the public key as well as the WebID from the certificate. As the WebID enables a global dereferencing mechanism for finding a key, the server uses can decide on dereferencing the WebID Profile and verify the claims about the WebID. Once the identity verification is established, the server can look up its access control rules for the requested resource to determine if and how the request can be fulfilled. Researchers can use servers and applications implementing the WebID-TLS workflow towards securely identifying profile claims and to have access to resources may be otherwise protected.</p>

              <p>There are a number of different ways to create a self-signed certificate which includes our WebID under SAN. Here we discuss a process that uses the <cite><a href="https://www.openssl.org/">OpenSSL</a></cite> toolkit as outlined in: <cite><a href="https://www.w3.org/wiki/index.php?title=Foaf%2Bssl/HOWTO#How_to_create_a_certificate_which_includes_the_WebID_URI_for_multi-purpose_use">How to create a certificate which includes the WebID URI for multi-purpose use</a></cite>. We can create an RSA key that can be used to SSH to networks, include WebID URI and email information in the SAN to create an X.509 certificate which can be used to sign digitally sign emails, as well as to authenticate with from the Web browser. The <cite>Issuer Distinguished Name</cite> in X.509 (<code class="highlight-x509-issuer">Issuer</code> field) identifies the entity that signs the certificate, hence self-signing. The X.509 certificate and the private key can be bundled with the <cite><a href="https://tools.ietf.org/html/rfc7292">PKCS #12</a></cite> archive file format, and imported in Web browser's certificate manager. The certificate consists of information along the lines of:</p>

              <figure class="listing">
                <pre><code>Certificate:</code>
<code>    Data:</code>
<code>        Version: 3 (0x2)</code>
<code>    Signature Algorithm: sha1WithRSAEncryption</code>
<code>        <span class="highlight-x509-issuer">Issuer</span>: O = http://csarven.ca/, OU = http://csarven.ca/, CN = Sarven Capadisli, emailAddress = info@csarven.ca</code>
<code>        Validity</code>
<code>            Not Before: Dec  8 14:11:55 2012 GMT</code>
<code>            Not After : Nov 14 14:11:55 2112 GMT</code>
<code>        Subject: O = http://csarven.ca/, OU = http://csarven.ca/, CN = Sarven Capadisli, emailAddress = info@csarven.ca</code>
<code>        Subject Public Key Info:</code>
<code>            <span class="highlight-x509-public-key-algorithm">Public Key Algorithm</span>: <span class="highlight-x509-rsa-public-key">rsaEncryption</span></code>
<code>                <span class="highlight-x509-modulus">Modulus</span>:</code>
<code>                    00:ca:f6:a7:8d:16:e8:0f:93:03:37:45:3d:84:f7:</code>
<code>                    90:76:4c:56:ea:58:ac:be:da:5d:e3:d1:7b:6e:67:</code>
<code>                    35:69:ef:58:1b:89:6b:74:46:66:55:fb:3d:a2:f9:</code>
<code>                    a9:61:c6:d4:6d:99:e7:70:53:a0:aa:f8:3f:ac:4e:</code>
<code>                    ab:8b:91:98:f2:09:30:67:2d:e2:2c:b1:b2:2f:0a:</code>
<code>                    b8:5a:66:c9:5a:68:30:ea:a7:be:1e:28:ec:19:7f:</code>
<code>                    f7:a4:a4:48:24:3a:f2:f2:06:d2:be:45:8b:bc:71:</code>
<code>                    f3:2a:a0:73:31:5e:22:c9:b2:66:8f:e1:5c:73:2a:</code>
<code>                    33:ed:cf:d9:fa:39:d0:47:06:19:10:44:f3:3e:58:</code>
<code>                    0f:95:4e:6a:1d:9c:4b:f0:8c:82:0c:46:66:f5:ef:</code>
<code>                    85:54:cf:14:30:a3:3b:63:0c:80:d1:1f:7d:30:9c:</code>
<code>                    b6:41:b2:13:fc:bf:c9:a5:b6:99:af:62:5f:e2:36:</code>
<code>                    27:c4:03:ff:12:d7:95:14:17:87:28:53:7a:a1:73:</code>
<code>                    ab:a5:bc:5a:eb:87:56:9e:ba:1b:e3:27:4a:a5:3d:</code>
<code>                    9b:2f:8f:e7:2f:13:ba:81:25:e7:34:e8:e3:11:28:</code>
<code>                    30:3c:76:59:43:27:c4:c2:e4:31:e3:8f:2b:32:6c:</code>
<code>                    c2:44:08:0e:59:7a:4d:27:a9:8a:e3:fe:1e:db:5d:</code>
<code>                    e7:85</code>
<code>                <span class="highlight-x509-exponent">Exponent</span>: 65537 (0x10001)</code>
<code>        X509v3 extensions:</code>
<code>            X509v3 <span class="highlight-x509-san">Subject Alternative Name</span>:</code>
<code>                email:info@csarven.ca, <span class="highlight-x509-uri">URI</span>:<span class="highlight-webid">http://csarven.ca/#i</span></code></pre>
                <figcaption>Example certificate including a WebID in Subject Alternative Name.</figcaption>
              </figure>

              <p><cite><a href="https://www.w3.org/ns/auth/cert">The Cert Ontology 1.0</a></cite> can be used in WebID Profile documents to specify an agent's certificate information. For example, an agent can indicate their public and private keys. The fields and corresponding values of <code class="highlight-x509-public-key-algorithm">Public Key Algorithm</code>, <code class="highlight-x509-modulus">Modulus</code>, and <code class="highlight-x509-exponent">Exponent</code> in the X.509 certificate are used in the WebID Profile as part of <code class="highlight-x509-rsa-public-key">cert:RSAPublicKey</code>, <code>cert:exponent</code>, and <code>cert:modulus</code>. <code class="highlight-x509-uri">URI</code> under <span class="highlight-x509-san">SAN</span> is our <span class="highlight-webid">WebID</span>. An example where information about an RSA Public Key is associated with a WebID:</p>

              <figure class="listing">
                <pre><code>&lt;<span class="highlight-webid">http://csarven.ca/#i</span>&gt;</code>
<code>  cert:key &lt;http://csarven.ca/#cert&gt; .</code>
<code></code>
<code>&lt;http://csarven.ca/#cert&gt;</code>
<code>  a <span class="highlight-x509-rsa-public-key">cert:RSAPublicKey</span> ;</code>
<code>  <span class="highlight-x509-exponent">cert:exponent</span> "65537"^^xsd:nonNegativeInteger ;</code>
<code>  <span class="highlight-x509-modulus">cert:modulus</span> "caf6a78d16e80f930337453d84f790764c56ea58acbeda5de3d17b6e673569ef581b896b74466655fb3da2f9a961c6d46d99e77053a0aaf83fac4eab8b9198f20930672de22cb1b22f0ab85a66c95a6830eaa7be1e28ec197ff7a4a448243af2f206d2be458bbc71f32aa073315e22c9b2668fe15c732a33edcfd9fa39d04706191044f33e580f954e6a1d9c4bf08c820c4666f5ef8554cf1430a33b630c80d11f7d309cb641b213fcbfc9a5b699af625fe23627c403ff12d79514178728537aa173aba5bc5aeb87569eba1be3274aa53d9b2f8fe72f13ba8125e734e8e31128303c76594327c4c2e431e38f2b326cc244080e597a4d27a98ae3fe1edb5de785"^^xsd:hexBinary .</code></pre>
                <figcaption>RSA Public Key information associated with a WebID URI.</figcaption>
              </figure>

              <p>WebID Profiles using the Cert Ontology can help authenticating servers to discover researchers public keys which can be used towards verifying identity claims.</p>

              <p id="webid-tls-delegation"><cite>WebID-TLS-Delegation</cite> is an an extension to WebID-TLS that enables users to delegate other agents to act on their behalf. In <cite><a href="http://ceur-ws.org/Vol-905/TrampEtAl_COLD2012.pdf">Extending the WebID Protocol with Access Delegation</a></cite>, Sebastian Tramp et al, states how a <q>principal</q> agent can delegate authentication and access to a trusted <q>secretary</q> agent - typically a third-party software - who can act <em>on behalf of</em> of the principal agent to perform (asynchronous) requests. A secretary with its own WebID acting on behalf of a user can potentially have the same (or required) privileges while still being distinguishable eg. via different public key, and capabilities. An agent can declare a delegation as follows:</p>

              <figure class="listing">
                <pre><code>&lt;<span class="highlight-webid">http://csarven.ca/#i</span>&gt;</code>
<code>  acl:delegates &lt;https://example.org/application#i&gt; .</code></pre>
                <figcaption>An agent delegating another agent to act on its behalf.</figcaption>
              </figure>

              <p>whereas the agent making requests on behalf of another agent would include the HTTP <code>On-Behalf-Of</code> header when making requests. The delegation mechanism</p>

              <p>The WebID-TLS workflow is based on open standards, broadly supported across platforms (covering servers, desktops, notebooks, phones, and other <abbr title="Internet of Things">IoT</abbr> devices), saves bandwidth, has low latency, and is simple to implement. Another attractive area for users using their own WebIDs along with self-signed certificates is that users can abstain from creating accounts for each Web application they use, as well as remember and manage usernames and passwords which are often vulnerable to phishing. A user sign-in process to authenticate themselves is as simple as "clicking" a button. Similarly, the certificate selection processed can be bypassed in that user can instruct its Web browser to select a certificate automatically if a server makes an authentication request. This sort of automatic authentication is not necessarily desirable for all interaction cases, simply because the user may wish to remain anonymous.</p>

              <p>On the other hand, there are important challenges with the WebID-TLS approach. First, creating certificates (including safely handling of private keys) in Operating Systems and/or Web browsers, and making them available to Web applications is not well-known to users and lack "simple" tooling. Second, the user experience around certificate management and selection in Web browsers as well as in different devices has a lot of room for improvement. Third, in order to minimise security risks, essentially tying identity to a certificate generally means that users are tied to the device on which their certificate was created - although it is possible to export and import certificates across devices, the steps in between are considered to be potentially weak points of the chain. One way to securely port the certificate with its private key is by encrypting the PKCS #12 archive with <a href="https://xkcd.com/936/">long and hard to guess</a> passphrases. In the event that the archive is stolen, there is at least a barrier which requires password cracking, and it may give sufficient time for the owner of the certificate to revoke it.</p>

              <p id="oidc"><cite><a href="https://openid.net/specs/openid-connect-core-1_0.html">OpenID Connect</a></cite> (<abbr title="OpenID Connect">OIDC</abbr>) is an authentication extension to <cite><a href="tools.ietf.org/html/rfc6749">The OAuth 2.0 Authorization Framework</a></cite>. OAuth 2.0 provides an authorization layer that separates the role of a client from that of the resource owner. Clients obtain an access token issued by an authorization server with the approval of a resource owner, and clients can use that delegation-specific credentials (access token) to obtain and use limited access to HTTP resources on the server. In addition to the authentication process, OIDC enables authorization servers to obtain profile information about the user.</p>

              <p id="webid-oidc"><cite><a href="https://github.com/solid/webid-oidc-spec">WebID-OIDC</a></cite> is an authentication delegation protocol resulting in OIDC's verified ID Token once a client authenticated, and deriving the WebID from the ID Token. The complete WebID-OIDC workflow as follows: an initial request is made to access a protected resource; whereby the user specifies their identity provider to the authorization server; the user authenticates themselves at the provider and gets redirected back to the resource they were trying to access and provides the signed ID Token; the server controlling the resource validates the token and extracts the WebID; and finally the confirmation from the resource server. For researchers, WebID-OIDC is equally applicable as WebID-TLS.</p>

              <hr />

              <p id="acl"><cite><a href="https://www.w3.org/ns/auth/acl">Access Control List</a></cite> (<abbr title="Access Control List">ACL</abbr>) ontology, enables a server to provide four modes of access: <q>Read</q>, <q>Write</q>, <q>Append</q>, and <q>Control</q>. As implied by the name, <em>read</em> allows a server's resources to be accessible and interpretable. <em>Write</em> allows resources to be modified or deleted. <em>Append</em> allows a specific kind of Write in that while adding of information is permitted, removal is not. <em>Control</em> permits full read and write access, which is typically given only to the owners (or administrators) of the resources.</p>

              <p>The following code snippets of authorization policies are used to specify the ACL information (eg. <samp>resource.acl</samp>) associated with a resource (eg. <samp>resource</samp>) on a server. For example, setting an authorization policy where an agent (only <code>http://csarven.ca/#i</code>) to be the owner of a resource:</p>

              <figure class="listing">
                <pre><code>&lt;#owner&gt;</code>
<code>  a acl:Authorization ;</code>
<code>  acl:agent &lt;http://csarven.ca/#i&gt; ;</code>
<code>  acl:accessTo &lt;./&gt; ;</code>
<code>  acl:mode acl:Control .</code></pre>
                <figcaption>An authorisation policy that assigns control access to an agent for a resource.</figcaption>
              </figure>

              <p>Setting a class of agents to perform read and append operations on a resource eg. an inbox:</p>

              <figure class="listing">
                <pre><code>&lt;#public&gt;</code>
<code>  a acl:Authorization ;</code>
<code>  acl:agentClass foaf:Agent ;</code>
<code>  acl:accessTo &lt;./&gt; ;</code>
<code>  acl:mode acl:Read , acl:Append .</code></pre>
                <figcaption>An authorisation policy that gives append access to a class of agents for a resource.</figcaption>
              </figure>

              <p>ACL plays a role in determining which authorization policies to apply when a researcher requests to access a resource.</p>
            </div>
          </section>



          <section id="persistence-and-preservation" inlist="" rel="schema:hasPart" resource="#persistence-and-preservation">
            <h2 property="schema:name">Persistence and Preservation</h2>
            <div datatype="rdf:HTML" property="schema:description">
              <p>As knowledge builds on knowledge, it is vital to preserve the connection between units of information in scholarly communication. There are a number of challenges in this respect. In this section we focus on the persistence of the identifiers for units, as well as content integrity and preservation of context. In the most general sense, trust and accessibility are integral to preservation of content, integrity, and the context in which they are used. This is so that knowledge can be scrutinised with the help of transparent trail of reproducibility and replicability of research results. We look at existing research and approaches in this space.</p>

              <p id="persistent-domains">As we have discussed in <cite><a href="decentralising-scholarly-communication#uri-ownership">URI ownership</a></cite>, domain name registration and maintenance is one of the key factors for long-term reliable persistence. Berners-Lee outlines two issues for the persistence of HTTP URIs:</p>

              <blockquote cite="https://www.w3.org/DesignIssues/PersistentDomains">
                <ol>
                  <li>The persistence of the opaque string which follows the domain name, and</li>
                  <li>the persistence of the domain name  itself.</li>
                </ol>
                <footer><cite><a href="https://www.w3.org/DesignIssues/PersistentDomains">Persistent Domains</a></cite>, 2000, Tim Berners-Lee</footer>
              </blockquote>

              <p id="cool-uris">In <cite><a href="http://www.w3.org/Provider/Style/URI">Cool URIs don't change</a></cite>, 1998, Berners-Lee discusses some of the approaches that can be taken towards usefulness and longevity of URIs. The article focuses on practices that a publisher making a commitment to persistence by designing and managing the URI path and the content it resolves to, as well as the domain name it uses. The "owner" of a domain name has the obligation to define what the things mean for its URIs. This is also a form of social contract made by the authority that names and defines a URI to anyone that's using it - see also <cite><a href="https://www.w3.org/DesignIssues/PhilosophicalEngineering">Philosophical Engineering and Ownerhip of URIs</a></cite> (sic).</p>

              <p id="persistence-policies">Persistence policies can come in different forms. For example, W3C's <a href="https://www.w3.org/Consortium/Persistence">URI Persistence Policy</a> is a document making a pledge about how some of the resources under its domain will persist throughout the lifetime of the Consortium; any changes to persistent resources will be archived; and in case that the organisation is disbanded, its resources can be made available under the same rights and license. These human-readable statements are useful institutional commitment to persistence. As mentioned earlier, the ODRL vocabulary can be used in a similar way to provide a machine-readable policy about resources.</p>

              <p id="uri-social-agreement">From the archiving perspective, Van de Sompel came to the conclusion that in a long enough timeline, HTTP URIs are not inherently persistent but persistable. The units of information that are registered using URIs are more of a promise made by its original or current authority. Hence, along with the examples from earlier, URI registration is ultimately a social agreement. URI owners declare a policy eg. implicit, written, verbal. If a policy is announced for a collection of URIs eg. what happens in 1000 years, then that says something about its intentions and expected level of availability. From this perspective, as discussed earlier in the <cite><a href="scholarly-communication-on-the-web#registration-of-identifiers-with-social-contracts">registration of identifiers with social contracts</a></cite>, <abbr title="Persistent Identifier">PID</abbr>s such as DOI, PURL, w3id, and ORCID can help to prolong such promises and to extend the lifetime of accessibility of units of scholarly information.</p>

              <p id="decentralized-identifiers"><cite><a href="https://w3c-ccg.github.io/did-spec/">Decentralized Identifiers</a></cite> (<abbr title="Decentralized Identifiers">DID</abbr>) are identifiers for verifiable <q>self-sovereign</q> digital identity, where they are <q>under the control of the subject, independent from any centralized registry, identity provider, or certificate authority.</q> In a way, DIDs go around the shortcomings of the domain name system where they can be created and managed without the authority of the registrar.</p>


              <p id="analyzing-the-persistence-of-referenced-web-resources-with-memento">In <cite><a data-versiondate="2018-09-01:15:15:43Z" data-versionurl="https://web.archive.org/web/20180901151543/https://arxiv.org/pdf/1105.3459.pdf" href="https://arxiv.org/pdf/1105.3459.pdf">Analyzing the Persistence of Referenced Web Resources with Memento</a></cite>, 2011, Sanderson et al present the results of a study on the persistence and availability of Web resources cited from research articles in two scholarly repositories. The results show that within a few years of the URL being cited, 45% of the URLs referenced from arXiv still exist but are not preserved, and 28% of the resources referenced by articles in the UNT digital library have been lost. In order to address this commonly known as URIs ceasing to exist (link rot), authors suggest that repositories expose the links in the articles through an API so that Web crawlers can be used to archive. With the help of archives supporting the Memento protocol, the original context of the citation can still be reconstructed.</p>

              <p id="reference-rot">Given the dynamic and ephemeral nature of the Web, and in particular management of URIs and corresponding representations at URLs, it poses a threat to integrity of Web-based scholarly content, and the consistency of scholarly records, as well as everywhere else. One special area is about the formal citation of scholarly resources (eg. DOI, HTTP-DOI-URI), and "informal" referencing of other resources on the Web (ie. any HTTP URI). The <cite><a href="http://hiberlink.org/">Hiberlink</a></cite> project investigates <q>reference rot</q> in Web-based scholarly communication, and introduces the term to denote two problems in using URI references:</p>

              <blockquote cite="https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0115253">
                <dl>
                  <dt id="link-rot">Link rot</dt>
                  <dd>The resource identified by a URI may cease to exist and hence a URI reference to that resource will no longer provide access to referenced content.</dd>
                  <dt id="content-drift">Content drift</dt>
                  <dd>The resource identified by a URI may change over time and hence, the content at the end of the URI may evolve, even to such an extent that it ceases to be representative of the content that was originally referenced.</dd>
                </dl>
                <footer><cite><a href="https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0115253">Scholarly Context Not Found: One in Five Articles Suffers from Reference Rot</a></cite>, 2014, Klein et al</footer>
              </blockquote>

              <p id="scholarly-context-not-found">In <cite><a href="https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0115253">Scholarly Context Not Found: One in Five Articles Suffers from Reference Rot</a></cite>, 2014, Klein et al acknowledge extensively studied phenomenon on link rot and content drift, and themselves <q>investigate the extent to which <em>reference rot</em> impacts the ability to revisit the web context that surrounds <abbr title="Science, Technology, and Medicine">STM</abbr> articles some time after their publication</q>. The results show that significant amount of HTTP URIs cited in STM articles are no longer responsive or adequate archived snapshots available. Authors state that it is impossible to adequately recreate the temporal context of the scholarly discourse, hence suggest that robust solutions are needed to combat the problem of reference rot. Authors can take practical steps to remedy some of these issues eg. using archives that support on-demand snapshots, embedding the archived URI with datetime information alongside the reference to the original resource - we discuss this further in <a href="#robust-links">Robust Links</a>.</p>

              <p id="scholarly-context-adrift">In <cite><a href="https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0167475">Scholarly Context Adrift: Three out of Four URI References Lead to Changed Content</a></cite>, Jones et al reuse the same dataset from Klein et al study, to investigate to what extent the textual content remained stable since the publication of the referencing article based on various well-established similarity measures based on the comparison of the representative Memento and the live resource. They <q cite="https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0167475">find that for over 75% of references the content has drifted away from what it was when referenced.</q> The authors support the idea that in order to partly work around this issue, authors should pro-actively create snapshots of the referenced resources at Web archives, and referencing them in their scholarly literature. However, the authors also state that such robust embedding in the infrastructure of the existing authoring, reviewing, and publishing workflow is still an open challenge. To that end, applying the <a href="#robust-links">Robust Links</a> (see below) approach can help. While the DOI-paradigm for scholarly units help to improve the link rot scenario when the custodians of the domains or the URLs of the scholarly resources relocate, the resources on the Web at large remain to be a problem given that their incentives towards longevity and access differ.</p>

              <p id="persistent-domains-content-drift">From the point of persistence of the domain name (losing ownership) as Berners-Lee describes, one kind of content drift would be if the content published at http://csarven.ca/ today may be different tomorrow if another authority gets to own csarven.ca and defines what goes there. Alternatively, it may be that the content at that location is dynamic, and could differ from one request to another. In both cases, content drift creates a situation where if the originally referenced resource is still the same. From the perspective of Web-based scholarly publications, changes to content - accidental or intentional - can impact the degree of reproducibility, replicability, comparability of research results, and maintaining a reliable scholarly record.</p>

              <p id="persistent-identifiers-for-scholarly-assets-and-the-web">In <cite><a data-versiondate="2018-09-01T16:01:52Z" data-versionurl="https://web.archive.org/web/20180901160152/http://www.ijdc.net/article/download/9.1.331/362/" href="http://www.ijdc.net/article/download/9.1.331/362/">Persistent Identifiers for Scholarly Assets and the Web: The Need for an Unambiguous Mapping</a></cite> Van de Sompel et al posit that while PIDs are assigned to resources outside of information access protocols (like HTTP), there is a need to unambiguously bridge the discovery of the Web-oriented resource eg. from PID to HTTP URI, in a way that is machine-actionable. For example, the PID paradigm has the following discovery path:</p>

              <ol>
                <li>PID is the resource identifier eg. <samp>10.2218/ijdc.v9i1.320</samp></li>
                <li>HTTP-URI-PID is the resolving URI eg. <samp>https://doi.org/10.2218/ijdc.v9i1.320</samp></li>
                <li>HTTP-URI-LAND is the redirect URI (landing page) eg. <samp>http://www.ijdc.net/article/view/9.1.331</samp></li>
                <li>HTTP-URI-LOC is the location URI of the content eg. <samp>http://www.ijdc.net/article/download/9.1.331/362/</samp></li>
              </ol>

              <p>Authors propose that using existing standards and practice, the essential ingredients for such a mapping is as follows. A PID has a Web equivalent HTTP-URI-PID, which is a requisite - minted by the naming authority. The HTTP-URI-PID can be content-negotiated to result in a) a human-readable representation at HTTP-URI-LAND or b) machine-readable representations with distinct HTTP-URI-MACH. The HTTP-URI-LAND remains the same for discovery, however, HTTP-URI-MACH uses an RDF-based approach to describe the aggregations of scholarly assets based on the OAI-ORE specification.</p>

              <p>It is worth briefly revisiting the notion of social agreements around Web resources. Conceptually the agreement that I make with you about the persistence of my website's resources is in essence the same as a naming authority controlling a PID, as well as all of the nodes in between HTTP-URI-LOC. The kind of mapping between a domain name and the IP address it points to is similar to a PID being mapped to a HTTP-URI-PID. Hence, URI Ownership boils down to two possibilities: either I "own" and control a URI space or someone else does.</p>

              <p id="cite-as">In <cite><a data-versiondate="2018-09-01T16:56:00Z" data-versionurl="https://web.archive.org/web/20180901165600/https://arxiv.org/pdf/1602.09102.pdf" href="https://arxiv.org/pdf/1602.09102.pdf">Persistent URIs Must Be Used To Be Persistent</a></cite>, Van de Sompel et al reveal the results of a study where authors do not use persistent URIs like DOIs even when available, and instead use the location URIs. In order to alleviate this issue, authors propose that an HTTP <code>Link</code> header is used at the location URI to announce the identifying HTTP-URI-PID. The current proposal is to use <cite><a href="https://tools.ietf.org/html/draft-vandesompel-citeas">cite-as: A Link Relation to Convey a Preferred URI for Referencing</a></cite> and a number of related patterns are outlined at <cite><a href="http://signposting.org/">Signposting the Scholarly Web</a></cite>.</p>

              <p id="robust-links"><cite><a data-versiondate="2018-09-01T17:01:57Z" data-versionurl="https://web.archive.org/web/20180901170157/http://robustlinks.mementoweb.org/spec/" href="http://robustlinks.mementoweb.org/spec/">Robust Links</a></cite>: are human and machine-actionable approaches to <q>decorate</q> links in hypertext documents so that the context of linked resources is preserved at the time of linking. Given that in a long enough time line, content-drift and link-rot pose challenges to maintain context and integrity between resources, associating the datetime information when linking helps to retain such context. The datetime information can be accompanied with a snapshot of the target URI made at a Web archive or a versioning system when linking, and using either the original or the versioned resource as the primary reference. Including datetime information in the source document can make it possible to interpret the context of each of the links in the document and to discover relevant snapshots. In the event that a linked resource or a snapshot becomes inaccessible, the datetime information helps to discover temporally close alternative snapshots.</p>

              <p id="trusty-uri"><cite><a href="http://trustyuri.net/">Trusty URI</a></cite> is a technique to include cryptographic hash values in URIs to uniquely associate them with an artifact. In <cite><a data-versiondate="2018-08-31T08:03:04Z" data-versionurl="https://web.archive.org/web/20180831080304/https://arxiv.org/pdf/1401.5775.pdf" href="https://arxiv.org/pdf/1401.5775.pdf">Trusty URIs: Verifiable, Immutable, and Permanent Digital Artifacts for Linked Data</a></cite>, 2014, Kuhn et al outline how specific resources and their entire reference trees can be verifiable. If the trusty URI of an artifact is known, it can be used to verify if the content of an artifact corresponds to what it is suppose to represent. This is useful to determine if the content is corrupted or manipulated. It follows that trusty URI artifacts are immutable as each version of a content generates a unique trusty URI. Trusty URI artifacts are considered to be permanent in that once archived or cached, the artifact can still be verified even if the original location is no longer available. Applications can use trusty URI to encode their own references, as well as compute an artifacts' trusty URI and verify before using it. Trusty URIs can be used to represent byte-level file content and for RDF graphs, and is compatible with named information URIs (<cite><a href="https://tools.ietf.org/html/rfc6920">Naming Things with Hashes</a></cite>). An example from the <cite><a href="http://trustyuri.net/spec/v1.FADQoZWcYugekAb4jW-Zm3_5Cd9tmkkYEV0bxK2fLSKao.md">Trusty URI Specification - Version 1</a></cite>: given resource <samp>http://example.org/r1</samp>, its trusty URI would be <samp>http://example.org/r1.<span class="highlight-trusty-module">RA</span>cbjcRIQozo2wBMq4WcCYkFAjRz0AX-Ux3PquZZrC68s</samp>, where <code class="highlight-trusty-module">RA</code> identifies the module as an RDF graph (independent of its serialization) of the resource, and the remaining characters signify the computed hash of the content.</p>

              <p id="nanopublications"><cite><a data-versiondate="2018-08-31T08:10:59Z" data-versionurl="https://web.archive.org/web/20180831081059/https://content.iospress.com/download/information-services-and-use/isu613?id=information-services-and-use%2Fisu613" href="https://content.iospress.com/download/information-services-and-use/isu613?id=information-services-and-use%2Fisu613">The Anatomy of a Nanopublication</a></cite>, 2010, Groth et al, propose to improve the efficiency in finding, connecting, and curating core scientific statements with associated context, with an annotation model and a format based on the RDF language realized with Named Graphs. The <cite><a data-versiondate="2018-09-01T13:06:43Z" href="http://nanopub.org/guidelines/working_draft/">Nanopublication Guidelines</a></cite>, 2015, specify how to denote unique RDF graphs for <em>assertions</em>, <em>provenance</em>, and <em>publication information</em>, which make up the body of a nanopublication that can be used as a single publishable and citable entity. Nanopublications can be independently used to expose and disseminate individual quantitative and qualitative structured scientific data, without being accompanied with narrative research articles. For example, hypothesis, claims, and negative results can exist on their own, be identifiable, and reused in different places, including embedded in research articles.</p>

              <p id="decentralized-provenance-aware-publishing-with-nanopublications">In <cite><a data-versiondate="2018-09-01T06:34:11Z" data-versionurl="https://web.archive.org/web/20180901063411/https://peerj.com/articles/cs-78/" href="https://peerj.com/articles/cs-78/">Decentralized provenance-aware publishing with nanopublications</a></cite>, 2016, Kuhn et al argue that due to publication and archival of scientific results is still based on print-centric workflows and commonly considered to be a responsibility of third-party publishers, there is currently no efficient, reliable, and agreed-upon Web-centric methods for publishing scientific datasets, and therefore a bottom-up process is necessary. To this end, the authors present a decentralised server network with a REST API to store, archive, find, and serve data in the form of nanopublications, where the identifiers for the units of information are based on the trusty URI method. The authors argue that the underlying architecture can serve as a reliable and <em>trustworthy</em> low-level semantic publishing, archiving, and data sharing layer that can be used by different knowledge domains.</p>

              <p id="linked-data-signatures"><cite><a data-versiondate="2018-09-01T13:40:00Z" href="https://w3c-dvcg.github.io/ld-signatures/">Linked Data Signatures</a></cite> is a mechanism to ensure authenticity and integrity of Linked Data documents through the use of public/private key cryptography. The digital signature is comprised of information about the i) signature suite that was used to create the signature, ii) parameters required to verify it, and iii) the signature value generated by the signature algorithm. The signature typically accompanies the Linked Data document so that the receiver can verify its authenticity using the available information.</p>
            </div>
          </section>


          <section id="decentralised-storage-and-interoperable-applications" inlist="" rel="schema:hasPart" resource="#decentralised-storage-and-interopearble-applications">
            <h2 property="schema:name">Decentralised Storage and Interoperable Applications</h2>
            <div datatype="rdf:HTML" property="schema:description">
              <p>Here we summarise some of the key characteristics of decentralised storage spaces, and expectations from servers and client applications which enable creation and use of scholarly and research information.</p>

              <p><em>Advantages of decentralised storage</em>: censorship resistance, persistent availability, self-monitoring, organic growth and optimisation, monopoly disruption, increased interest in privacy and security.</p>

              <p><em>Disadvantages of decentralised storage</em>:</p>

              <p id="pod"><em>Personal online datastore</em> (<abbr title="pod">pod</abbr>) can be used synonymously with <em>dataspaces</em>, and loosely refers to an individual-operated Web space with mechanisms for data storage that is capable of providing read-write operations for independently built interoperable applications. A generic pod can be virtually realised with any HTTP server with varying configurations and capabilities offering advanced client-side applications to communicate with it. Web resources that are only intended for public read entails that the custodian allows resources to be available in response to client requests. Servers permitting write operations would need to factor in an authentication mechanism and authorization rules to determine who to serve the resources to and under which access constraints. A server-client interaction based on a read-write Linked Data architecture has affordances for distributed and semantically interconnected Web resources.</p>
  
              <p id="pod-expectation">An individual responsible for a pod entails that they responsible as well as accountable of its operation, abilities, policies and practice decisions on data, persistence strategies and so forth. Running a pod fundamentally requires the system to fulfil the registration function for the content it makes available. As archiving is an external function, we expect other services to meet that requirement. The certification function can be fulfilled in a similar manner to registration in that the actors that are involved in the quality-control process can register their own units of information in their pod in response to target units.</p>

              <p>Application characteristics: Interactions based on interoperable Web standards enables servers and clients to communicate </p>

              <table id="specifications-for-forces-and-functions">
                <caption>Specifications to fulfil forces and functions in scientific communication</caption>
                <thead>
                  <tr>
                    <th rowspan="2">Specification</th>
                    <th colspan="4">Forces</th>
                    <th colspan="4">Functions</th>
                  </tr>
                  <tr>
                    <th>Actor</th>
                    <th>Accessibility</th>
                    <th>Content</th>
                    <th>Applicability</th>
                    <th>Registration</th>
                    <th>Awareness</th>
                    <th>Certification</th>
                    <th>Archiving</th>
                  </tr>
                </thead>
                <tbody>
                  <tr><th colspan="9" scope="rowgroup">Protocol</th></tr>
                  <tr><th>Linked Data Platform</th><td></td><td>âœ”</td><td>âœ”</td><td></td><td>âœ”</td><td>âœ”</td><td></td><td></td></tr>
                  <tr><th>Linked Data Templates</th><td></td><td>âœ”</td><td>âœ”</td><td></td><td>âœ”</td><td>âœ”</td><td></td><td></td></tr>
                  <tr><th>Linked Data Fragments</th><td></td><td>âœ”</td><td>âœ”</td><td></td><td></td><td>âœ”</td><td></td><td></td></tr>
                  <tr><th>Fedora API</th><td>âœ”</td><td>âœ”</td><td>âœ”</td><td></td><td>âœ”</td><td>âœ”</td><td></td><td>âœ”</td></tr>
                  <tr><th>Memento</th><td></td><td>âœ”</td><td></td><td></td><td>âœ”</td><td>âœ”</td><td></td><td>âœ”</td></tr>
                  <tr><th>Web Annotation</th><td></td><td>âœ”</td><td>âœ”</td><td></td><td>âœ”</td><td>âœ”</td><td>âœ”</td><td></td></tr>
                  <tr><th>ActivityPub</th><td>âœ”</td><td>âœ”</td><td>âœ”</td><td></td><td>âœ”</td><td>âœ”</td><td>âœ”</td><td></td></tr>
                  <tr><th>Linked Data Notifications</th><td></td><td>âœ”</td><td>âœ”</td><td></td><td>âœ”</td><td>âœ”</td><td></td><td></td></tr>
                  <tr><th>WebID</th><td>âœ”</td><td></td><td>âœ”</td><td></td><td>âœ”</td><td></td><td></td><td></td></tr>
                  <tr><th>WebID-TLS</th><td>âœ”</td><td>âœ”</td><td>âœ”</td><td></td><td></td><td></td><td></td><td></td></tr>
                </tbody>
                <tbody>
                  <tr><th colspan="9" scope="rowgroup">Model</th></tr>
                  <tr><th>Web Access Control</th><td>âœ”</td><td>âœ”</td><td></td><td></td><td></td><td></td><td></td><td></td></tr>
                  <tr><th>Hydra Core</th><td></td><td>âœ”</td><td>âœ”</td><td></td><td></td><td>âœ”</td><td></td><td></td></tr>
                  <tr><th>Activity Streams</th><td>âœ”</td><td></td><td>âœ”</td><td>âœ”</td><td>âœ”</td><td>âœ”</td><td>âœ”</td><td></td></tr>
                  <tr><th>Robust Links</th><td></td><td></td><td>âœ”</td><td></td><td></td><td>âœ”</td><td></td><td>âœ”</td></tr>
                </tbody>
                <tfoot>
                  <tr>
                    <td colspan="9">
                      <p>The suit of Web Annotation standards are grouped. Triple Pattern Fragments is grouped into Linked Data Fragments. WebID incorporates identification systems that can be used for actors (PURL, w3id, ORCID), as well as the WebID Profile that describes it.</p>
                    </td>
                  </tr>
                </tfoot>
              </table>


              <p><strong>Desired qualities</strong>: Based on aforementioned research, standards, and practices in the field towards Web-based personal identifiers and representations, we can infer a set of qualities that can empower individuals when participating in a decentralised scholarly system:</p>

              <ul>
                <li>Self-hosted and individually-controlled personal identifiers denoted with HTTP URIs</li>
                <li>Profile customisability and connectivity</li>
                <li>Linkable multiple identities</li>
                <li>Identity privacy and control</li>
              </ul>


              <p>We can observe different degrees of control:</p>

              <figure id="degree-of-control">
                <pre>                      |------ URI ownership ------|
Individual controlled |------ Data----------------| Third-party controlled
                      |------ Applications -------|</pre>
                <figcaption>Degree of control (individual or third-party) for URI ownership, data, and applications</figcaption>
              </figure>

              <p>On one end of the spectrum, an individual registers their own domain name, hosts their personal storage, and uses applications of their choosing. With that, they have highest degree of autonomy for their online presence and interactions. On the other end of the spectrum, an individual's identifier as well as a range of expressible identities, the data location and conditions of use, and assigned applications by third-party services.</p>

              <p>Different degrees of control would influence the forces and functions in scholarly communication. For instance, while ORCID is third-party controlled, it is possible to customise the profile to link to other identities. Similarly, the profile description can indicate the location of researcher's personal online storage, inbox, as well as outbox, which can controlled by the individual. An application built with interoperable open Web standards can potentially communicate with services that conform to the same protocols and data models.</p>
            </div>
          </section>



          <section id="the-effects-and-artefacts-of-autonomous-engagement" inlist="" rel="schema:hasPart" resource="#the-effects-and-artefacts-of-autonomous-engagement">
            <h2 property="schema:name">The Effects and Artefacts of Autonomous Engagement</h2>
            <div datatype="rdf:HTML" property="schema:description">
              <p>We can reuse the same set of questions raised in <cite>Systematizing Decentralization and Privacy</cite> to study the design choices made in our researcher-centric scholarly system:</p>

              <p>The Webâ€™s design stands out because of its absence of centralised control, both for technical reasons of scalability and resilience as well as a societal need for freedom of expression. A challenge in such large-scale decentralised networks is how related publications can be semantically interlinked, even if they are authored and published by different parties. Centralising their publications is practiced by the majority of authoring networks today, demanding authors to give up some or all of their control in exchange for technical simplicity.</p>

              <p>We can approach an alternative to this centralisation by adopting Web-centric worfklows that are inherently interoperable by design, but most importantly by enabling the creators and the users of data and applications to be autonomous entities, working towards the democratisation of scholarly knowledge for humans and machines. One way to achieve this is by decentralisation and decoupling of data and applications. While interoperability and application switching benefits the creators and users of the information, a 2017 report by The Media Lab, <cite><a data-versiondate="2017-08-18T21:06:41Z" data-versionurl="https://web.archive.org/web/20170818210641/http://dci.mit.edu/assets/papers/decentralized_web.pdf" href="http://dci.mit.edu/assets/papers/decentralized_web.pdf">Defending Internet Freedom through Decentralization: Back to the Future?</a></cite>, contents that <q cite="http://dci.mit.edu/assets/papers/decentralized_web.pdf">doing so threatens the business model of these companies, which rely on uniquely collecting and monetizing user data</q>, and that the approach is unlikely to be taken up by the big players directly. In <cite><a data-versiondate="2018-08-30T10:14:19Z" data-versionurl="https://web.archive.org/web/20180830101419/https://blog.dshr.org/2018/01/it-isnt-about-technology.html" href="https://blog.dshr.org/2018/01/it-isnt-about-technology.html">It Isn't About the Technology</a></cite>, Rosenthal while agrees with issue that MIT report raises, and adds that even if decentralisation and interoperable systems were increasingly adopted, academic institutions for instance would likely outsource parts of that infrastructure to <q>the cloud</q> where publishers would apply a strategy like Microsoft's <q>embrace, extend and extinguish</q>.</p>

              <hr />

              <p>The future of self-registration of scholarly units depends in large part on how well its practitioners, advocates, educators alike, are able to reconcile the ideals that the medium offers with the realities of the commercial third-party systems within which scholarly communication operates and the homogenizing influences of scholarly socialisation.</p>

              <p>While these challenges are technically surmountable, they need to be taken seriously if, the extreme case where "anyone can say anything about anything" is subject to be treated on equal grounds as a piece of information that is well certified. One contemporary and popular example of this scenario is where nearly all scientists being in agreement on the presence of global warming, climate change, and its consequences. In order to honour a commitment to public service, scientific communication - independent to self-registration - must remain grounded on reproducible and/or replicable facts and explanations, attributable and accountable participants. After all, the output affects journalism, further scientific knowledge exchange, policy making, as well public opinion and perception.</p>

              <p>Decentralised authoring, publication, and annotation furthermore have the potential to impact areas in which centralised services currently determine the pace of evolution. Scientific publishing, for instance, is often bound to centralised review and dissemination processes. Instead, rigorous scientific discourse can still be realised with an open, decentralised environment for the annotation of manuscripts, which can potentially reach interested parties in a timely manner. Trust then no longer stems from a finite process with limited transparency, but is rather continuously assessed by repeated independent validation. Publication thereby becomes the starting point rather than the end point of the scholarly communication process.</p>

              <hr />

              <p id="non-functional-requirements"><strong>Non-Functional Requirements</strong>: While there are plethora of <cite>architecturally significant requirements</cite> such as institutional or orientations in society and industry, we focus on non-functional and functional requirements which enable personal and academic freedom, in particular to creating affordances towards autonomy and interoperable participation on the open Web. Given above initiatives and developments, we derive non-functional requirements for systems to aim at addressing the forces and functions in scientific communication through the following:</p>

              <ul>
                <li><em>Interoperability</em> to improve discovery, accessibility, integrability, and reusability</li>
                <li><em>Security and privacy</em></li>
                <li><em>Modularity and extensibility</em></li>
                <li><em>Data integrity, transparency, and reliability</em></li>
                <li><em>Persistence and preservation</em></li>
                <li>...</li>
              </ul>

            </div>
          </section>

        </div>
      </article>
    </main>
  </body>
</html>
