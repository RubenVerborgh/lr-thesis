<!DOCTYPE html>
<html lang="en" xml:lang="en" xmlns="http://www.w3.org/1999/xhtml">
  <head>
    <meta charset="utf-8" />
    <title>Structure of Scholarly Information</title>
    <meta content="width=device-width, initial-scale=1" name="viewport" />
    <link href="media/css/basic.css" media="all" rel="stylesheet" title="Basic" />
    <link href="media/css/thesis.css" media="all" rel="stylesheet alternate" title="Thesis" />
    <link href="media/css/lncs.css" media="all" rel="stylesheet alternate" title="LNCS" />
    <link href="media/css/acm.css" media="all" rel="stylesheet alternate" title="ACM" />
    <link href="media/css/dokieli.css" media="all" rel="stylesheet" />
    <script src="scripts/dokieli.js"></script>
  </head>

  <body about="" prefix="rdf: http://www.w3.org/1999/02/22-rdf-syntax-ns# rdfs: http://www.w3.org/2000/01/rdf-schema# owl: http://www.w3.org/2002/07/owl# xsd: http://www.w3.org/2001/XMLSchema# dcterms: http://purl.org/dc/terms/ dctypes: http://purl.org/dc/dcmitype/ foaf: http://xmlns.com/foaf/0.1/ pimspace: http://www.w3.org/ns/pim/space# cc: https://creativecommons.org/ns# skos: http://www.w3.org/2004/02/skos/core# prov: http://www.w3.org/ns/prov# mem: http://mementoweb.org/ns# qb: http://purl.org/linked-data/cube# earl: http://www.w3.org/ns/earl# schema: http://schema.org/ void: http://rdfs.org/ns/void# rsa: http://www.w3.org/ns/auth/rsa# cert: http://www.w3.org/ns/auth/cert# wgs: http://www.w3.org/2003/01/geo/wgs84_pos# bibo: http://purl.org/ontology/bibo/ sioc: http://rdfs.org/sioc/ns# doap: http://usefulinc.com/ns/doap# dbr: http://dbpedia.org/resource/ dbp: http://dbpedia.org/property/ sio: http://semanticscience.org/resource/ opmw: http://www.opmw.org/ontology/ deo: http://purl.org/spar/deo/ doco: http://purl.org/spar/doco/ cito: http://purl.org/spar/cito/ fabio: http://purl.org/spar/fabio/ oa: http://www.w3.org/ns/oa# as: https://www.w3.org/ns/activitystreams# ldp: http://www.w3.org/ns/ldp# solid: http://www.w3.org/ns/solid/terms# acl: http://www.w3.org/ns/auth/acl# dio: https://w3id.org/dio# rel: https://www.w3.org/ns/iana/link-relations/relation#" typeof="schema:CreativeWork sioc:Post prov:Entity">
    <main>
      <article about="" typeof="schema:ScholarlyArticle">
        <h1 property="schema:name">Structure of Scholarly Information</h1>

        <div id="authors">
          <dl id="author-name">
            <dt>Authors</dt>
            <dd id="Sarven-Capadisli" inlist="" rel="bibo:authorList" resource="http://csarven.ca/#i"><span about="" rel="schema:creator schema:publisher schema:author"><a about="http://csarven.ca/#i" href="http://csarven.ca/" property="schema:name" rel="schema:url" typeof="schema:Person"><span about="http://csarven.ca/#i"><span property="schema:givenName">Sarven</span> <span property="schema:familyName">Capadisli</span></span></a></span><sup>✊</sup></dd>
          </dl>
        </div>

        <dl id="document-identifier">
          <dt>Identifier</dt>
          <dd><a href="https://linkedresearch.org/article/csarven.ca/structure-of-scholarly-information" rel="owl:sameAs">https://linkedresearch.org/article/csarven.ca/structure-of-scholarly-information</a></dd>
        </dl>

        <dl id="document-created">
          <dt>Created</dt>
          <dd><time content="2017-09-25T00:00:00Z" datatype="xsd:dateTime" datetime="2017-09-25T00:00:00Z" property="schema:dateCreated">2017-09-25</time></dd>
        </dl>

        <dl id="document-published">
          <dt>Published</dt>
          <dd><time content="2017-09-25T00:00:00Z" datatype="xsd:dateTime" datetime="2017-09-25T00:00:00Z" property="schema:datePublished">2017-09-25</time></dd>
        </dl>

        <dl id="document-modified">
          <dt>Modified</dt>
          <dd><time content="2018-10-15T22:50:08.921Z" datatype="xsd:dateTime" datetime="2018-10-15T22:50:08.921Z" property="schema:dateModified">2018-10-15</time></dd>
        </dl>

        <dl id="document-latest-version">
          <dt>Latest Version</dt>
          <dd><a href="https://linkedresearch.org/article/csarven.ca/5676c06b-364e-4223-ac40-dac4d3e4d17c" rel="mem:memento rel:latest-version">https://linkedresearch.org/article/csarven.ca/5676c06b-364e-4223-ac40-dac4d3e4d17c</a></dd>
        </dl>

        <dl id="document-timemap">
          <dt>TimeMap</dt>
          <dd><a href="https://linkedresearch.org/article/csarven.ca/structure-of-scholarly-information.timemap" rel="mem:timemap">https://linkedresearch.org/article/csarven.ca/structure-of-scholarly-information.timemap</a></dd>
        </dl>

        <dl id="document-derived-from">
          <dt>Derived From</dt>
          <dd>
            <ul>
              <li><a href="https://dokie.li/docs" rel="prov:wasDerivedFrom">dokieli documentation</a></li>
              <li><a href="http://csarven.ca/this-paper-is-a-demo" rel="prov:wasDerivedFrom">This ‘Paper’ is a Demo</a></li>
              <li><a href="http://csarven.ca/sparqlines-sparql-to-sparkline" rel="prov:wasDerivedFrom">Sparqlines: SPARQL to Sparkline</a></li>
              <li><a href="https://www.w3.org/TR/annotation-html" rel="prov:wasDerivedFrom">Embedding Web Annotations in HTML</a></li>
              <li><a href="https://github.com/linkeddata/dokieli/wiki#examples-in-the-wild" rel="prov:wasDerivedFrom">dokieli Examples in the Wild</a></li>
              <li><a href="https://github.com/ceurws/ceur-make" rel="prov:wasDerivedFrom">ceur-make</a></li>
              <li><a href="http://semstats.org/" rel="prov:wasDerivedFrom">SemStats</a></li>
              <li><a href="https://linkedresearch.org/resources" rel="prov:wasDerivedFrom">Linked Research resources</a></li>
              <li><a href="https://linkedresearch.org/events/eswc2017/" rel="prov:wasDerivedFrom">Enabling Decentralised Scholarly Communication</a></li>
              <li><a href="https://linkedresearch.org/calls" rel="prov:wasDerivedFrom">Call for Linked Research</a></li>
              <li><a href="https://linkedresearch.org/ldn/tests/summary" rel="prov:wasDerivedFrom">LDN Test Reports and Summary</a></li>
              <li><a href="http://csarven.ca/linked-specifications-reports" rel="prov:wasDerivedFrom">Linking Specifications, Test Suites, and Implementation Reports</a></li>
              <li><a href="http://csarven.ca/enabling-accessible-knowledge" rel="prov:wasDerivedFrom">Enabling Accessible Knowledge</a></li>
            </ul>
          </dd>
        </dl>

        <dl id="document-license">
          <dt>License</dt>
          <dd><a href="https://creativecommons.org/licenses/by/4.0/" rel="schema:license" title="Creative Commons Attribution 4.0 Unported">CC BY 4.0</a></dd>
        </dl>

        <dl id="document-inbox">
          <dt>Notifications Inbox</dt>
          <dd><a href="https://linkedresearch.org/inbox/csarven.ca/5676c06b-364e-4223-ac40-dac4d3e4d17c/" rel="ldp:inbox">https://linkedresearch.org/inbox/csarven.ca/5676c06b-364e-4223-ac40-dac4d3e4d17c/</a></dd>
        </dl>

        <dl id="document-annotation-service">
          <dt>Annotation Service</dt>
          <dd><a href="https://linkedresearch.org/annotation/csarven.ca/5676c06b-364e-4223-ac40-dac4d3e4d17c/" rel="oa:annotationService">https://linkedresearch.org/annotation/csarven.ca/5676c06b-364e-4223-ac40-dac4d3e4d17c/</a></dd>
        </dl>

        <dl id="document-in-reply-to">
          <dt>In Reply To</dt>
          <dd><a href="https://linkedresearch.org/calls" rel="as:inReplyTo">Call for Linked Research</a></dd>
        </dl>

        <dl id="document-status">
          <dt>Document Status</dt>
          <dd rel="pso:holdsStatusInTime" resource="#31943b7f-b646-4ebd-8787-ec2341e862c1"><span rel="pso:withStatus" resource="http://purl.org/spar/pso/draft" typeof="pso:PublicationStatus">Draft</span></dd>
        </dl>

        <div datatype="rdf:HTML" property="schema:description">
          <section id="information-spaces" inlist="" rel="schema:hasPart" resource="#information-spaces">
            <h2 property="schema:name">Information Spaces</h2>
            <div datatype="rdf:HTML" property="schema:description">
              <p>Given that global strategic research is influenced by policies and industry, different <em>information spaces</em> can be created by an ensemble of units of information. Such information spaces would serve to facilitate knowledge exchange in the scientific communication market. In this section, I investigate existing approaches towards configuring different aspects of Web-centric information spaces.</p>

              <p>Scholarly knowledge includes a range of research artefacts that needs to be described, uniquely identifiable and be discoverable on the Web. These include research articles, peer reviews, research data, social interactions like review requests and notifications in general, as well as different kinds of annotations on research objects. The current state of access and use of scholarly knowledge is insufficient for society at large. By enabling accessible <q href="http://drops.dagstuhl.de/opus/volltexte/2019/10328/pdf/dagrep_v008_i009_p029_18371.pdf#subsection.3.25">Scholarly Knowledge</q> (<cite><a data-versiondate="2019-03-25T11:19:30Z" data-versionurl="https://web.archive.org/web/20190325111930/http://drops.dagstuhl.de/opus/volltexte/2019/10328/pdf/dagrep_v008_i009_p029_18371.pdf" href="http://drops.dagstuhl.de/opus/volltexte/2019/10328/pdf/dagrep_v008_i009_p029_18371.pdf">Knowledge Graphs: New Directions for Knowledge Representation on the Semantic Web</a></cite>) graphs as well as applications which make use of it, we hope to enable universal access to previous research. By improving the availability through linked research, we can facilitate discovery and building on existing research. A fundamental first step is to investigate and develop effective ways to represent fine-grained information that is accessible, human and machine-interpretable, and interconnected.</p>

              <p>Figure X depicts a typical high-level interplay between the <em>actors</em> and the <em>content</em> forces, and their functions (registration, awareness, certification, archive) in scholarly communication. Given that the <em>accessibility</em> and <em>applicability</em> are external forces in scientific communication, I assume that they are already integrated in this information space.</p>

              <figure id="figure-linked-research-ecosystem" rel="schema:hasPart" resource="#figure-linked-research-ecosystem">
                <object data="/proxy?uri=http://csarven.ca/media/images/articles/linked-research-ecosystem.svg" height="243" rel="schema:image" type="image/svg+xml" width="480"></object>

                <figcaption property="schema:name">Linked Research ecosystem</figcaption>
              </figure>

              <p>Here authors create research literature in reply to a call for contributions; reviewers provide feedback on the research results; individuals annotate and re-share the literature; editors filter and assemble a collection of work; archives are notified about the research. While the document-centric Web was mostly for human-readability, Linked Data-based Web is oriented towards improving discoverability, readability, and reuse for machines. For example, if research articles capture their <a href="http://csarven.ca/web-science-from-404-to-200#problem-space" rel="cito:citesAsEvidence">problem statements</a>, <a href="http://csarven.ca/call-for-linked-research#no-central-authority" rel="cito:citesAsEvidence">motivation</a>, <a href="http://csarven.ca/sense-of-lsd-analysis#hypothesis-null" rel="cito:citesAsEvidence">hypothesis</a>, <a href="http://csarven.ca/cooling-down-web-science#introduction" rel="cito:citesAsEvidence">arguments</a>, <a href="http://csarven.ca/enabling-accessible-knowledge#workflow" rel="cito:citesAsEvidence">workflow steps</a>, <a href="http://csarven.ca/sense-of-lsd-analysis#methodology" rel="cito:citesAsEvidence">methodology</a>, <a href="http://csarven.ca/linked-data-notifications#protocol" rel="cito:citesAsEvidence">design</a>, <a href="http://csarven.ca/linked-statistical-data-analysis#results" rel="cito:citesAsEvidence">results</a>, <a href="http://csarven.ca/linked-data-notifications#analysis-and-evaluation" rel="cito:citesAsEvidence">evaluation</a>, <a href="http://csarven.ca/linked-research-scholarly-communication#conclusions" rel="cito:citesAsEvidence">conclusions</a>, <a href="http://csarven.ca/dokieli#next-steps" rel="cito:citesAsEvidence">future challenges</a>, as well as all <a href="https://dokie.li/#figure-dokieli-citation" rel="cito:citesAsEvidence">inline semantic citations</a> (to name <em>a few</em>) where they are uniquely identified, related to other data, and discoverable, then specialised software can be used to verify the article’s well-formedness with respect to the domain. In essence, this materialises the possibility of articles being executable towards reproduction of computational results. Similarly, user interfaces can manifest environments where readers can rerun experiments or observe the effects of changing the input parameters of an algorithm. This has the affordance for a more <a href="http://worrydream.com/LadderOfAbstraction/" title="Up and Down the Ladder of Abstraction">involving environment for the user</a>, improves learnability of material, and supersedes the passive mode of reading.</p>

              <p id="practical-knowledge-representation-for-the-web">In 1999 article, <cite><a data-versiondate="2018-12-29T16:45:15Z" data-versionurl="https://web.archive.org/web/20181229164515/https://www.cs.vu.nl/~frankh/postscript/IJCAI99-III.html" href="https://www.cs.vu.nl/~frankh/postscript/IJCAI99-III.html">Practical Knowledge Representation for the Web</a></cite>, Van Harmelen, 1999, stated that <q>the lack of semantic markup is a major barrier to the development of more intelligent document processing on the Web</q>, and <q>meta-data annotation of Web sources is essential for applying AI techniques on a large and successful scale</q>, which at large, remain as open issues today.</p>

              <p>In this section I examine some of the existing Web standards and practices for the structure and semantics of scholarly information with focus on narrative documents and observational data. Scholarly documents with the characteristics of a continuous prose, such as those of research articles typically includes factual information about an investigation with supporting provenance-level information and references to underlying data. Annotations in the general sense can be similar to articles, however they are generally intended to encapsulate an indirection where target resources are associated with annotation activities with motivations, eg. commenting, bookmarking, or classifying. Notifications for scholarly activities serve as a way to inform a target of interest about events in general. I also examine representation and publication of statistical, experimental, or observational data on the Web following the Linked Data design principles.</p>

              <p>One goal here is to identify and apply patterns so that content creators can "register" different units of information at varying semantic granularity. Ultimately, I seek solutions that embrace interoperability and reusability, device and medium independence, as well as favourable for accessibility and archiving.</p>
            </div>
          </section>


          <section id="structure-and-semantics" inlist="" rel="schema:hasPart" resource="#structure-and-semantics">
            <h2 property="schema:name">Structure and Semantics</h2>
            <div datatype="rdf:HTML" property="schema:description">
              <p>The structure of a scholarly journal article has been mostly conserved during the evolution of scientific communication. A typical scholarly article may include a sequence of sections, usually an abstract; introduction and background relevant to earlier work; methods used to justify experiments; research results; discussion and conclusions; and a list of references. Different forms of research eg. original, scientific, artistic, or research in the humanities, may have their own discipline-centric organisational structures for the journal article. For example, <em>Introduction, Methods, Results, and Discussion</em> (<abbr title="Introduction, Methods, Results, and Discussion">IMRAD</abbr>) is a <a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC442179/">widely adopted standardised structure</a> in original research articles. In the medical domain, <em>structured abstracts</em> are used to help with rapid comprehension by having distinct labelled sections, eg. introduction, objects, methods, results, conclusions, within the abstract of the article.</p>

              <p>This section covers semantic structure of the narrative aspects scholarly communication. This can enhance <em>both</em> human- and machine-readability of information, in particular, representations of units irrespective of how they are produced.</p>

              <p>Non-narrative units can also be semantically represented to enable easier reuse and interpretation; this is covered in more detail in <a href="#linked-statistics">Linked Statistics</a> and <cite><a href="decentralised-linked-research-application#interactive-linked-statistics">Interactive Linked Statistics</a></cite>.</p> 

              <section id="units-of-communication" inlist="" rel="schema:hasPart" resource="#units-of-communication">
                <h3 property="schema:name">Units of Communication</h3>
                <div datatype="rdf:HTML" property="schema:description">
                  <p>Researchers exchange <q cite="http://www.dlib.org/dlib/september04/vandesompel/09vandesompel.html">units of communication</q> like scientific literature, annotation, datasets, workflows, argumentation, provenance, citation, and software. Knowledge may be represented or presented dynamically, or as a compilation of various independent units (compound). Semantic structure may be embedded in narrative or prose-based scholarly communication as well as used to enhance non-narrative units like experimental results or datasets. Narrative and non-narrative units may in turn include or refer to each other.</p>

                  <p>While Web resources and their representations can be composed of different kinds of hypermedia, I focus on those that are generally referred to as <q>documents</q>. For instance, articles, annotations, notifications, and profiles when combined can cover a wide range of use cases with respect to units of communication. Each instantiation share common characteristics in that they can be both human and machine-readable - forming a <q><a data-versiondate="2019-03-25T11:19:30Z" data-versionurl="https://web.archive.org/web/20190325111930/http://drops.dagstuhl.de/opus/volltexte/2019/10328/pdf/dagrep_v008_i009_p029_18371.pdf" href="http://drops.dagstuhl.de/opus/volltexte/2019/10328/pdf/dagrep_v008_i009_p029_18371.pdf">knowledge graph</a></q> in their own right.</p>

                  <dl>
                    <dt>Article</dt>
                    <dd>An article in the most general sense is a domain-agnostic unit of information encoded in a document. Research contributions including, manuscripts, reports, assessments, technical specifications, news, social media posts and slideshows are some examples for different kinds of articles.</dd>

                    <dt>Annotation</dt>
                    <dd>Annotations include information that is generally about an association between resources with different intentions. For example, assessing, commenting, liking, bookmarking, describing, linking, are some of the motivations to annotate an article.</dd>

                    <dt>Notification</dt>
                    <dd>Notifications generally express actor activities. For example, announcements about a scientific article or parts within; a quality assessment of some literature; reports of observations; annotations or social activities.</dd>

                    <dt>Profiles</dt>
                    <dd>Actors have online profiles where they generally describe themselves, refer to their contacts (address books) or curriculum vitae.</dd>
                  </dl>
                </div>
              </section>


              <section id="human-and-machine-readable-information" inlist="" rel="schema:hasPart" resource="#human-and-machine-readable-information">
                <h3>Human and Machine-Readable Information</h3>
                <div>
                  <p id="human-machine-readable">A <dfn>human-readable format</dfn> (or medium) is a representation of information that enables humans to read, edit, or act upon. A <dfn>machine-readable format</dfn> entails that information can be effectively stored and processed by a machine. Both approaches are equipped with <a href="#affordance">affordances</a> that can be used by respective agents.</p>

                  <p id="declarative-programming-paradigm"><strong>Declarative programming paradigm</strong>: Declarative programming is a style of building the structure and expressing the semantics of programs, ie. <em>what</em> it should accomplish. The imperative programming style on the other hand is about <em>how</em> the program should execute and change the program state. The declarative approach tends to be short, easy to understand, independent of implementation, less likely to contain errors as well as to easily correct, and tractable. For example, many domain-specific markup languages, such as HTML and XML-family (XSLT, SVG, MathML), and CSS are declarative. HTML simply tells the consuming agent - like a Web browser - what should appear as part of a Webapage. HTML's readability and ease of interpretation played a role in its adoption - anyone that wanted to express some information in a Webpage can "view source" to learn without any further steps.</p>

                  <p id="rdf-as-the-language"><strong>RDF as the language</strong>: HTML is a prominent media form to publish on the Web. While this is sufficient to cover various use cases in a scholarly information space, it is limited in the sense that the granularity of machine-readable content is based on the classic hypertext model, ie. ultimately a relationship with loose semantics between documents or their parts. It is considered to be limited in terms of capturing domain-specific knowledge. This is in contrast to using RDF as the language to communicate knowledge about arbitrary things at different levels of abstraction. Atomic statements about scientific information and scholarly activities can be expressed, as well as each component of a statement being universally identifiable. The language enables the information to be serialised using different syntaxes eg. HTML+RDFa, Turtle. Perhaps most importantly, the underlying data is intended to be manipulated as a <em>graph</em> of things, where its syntactical representations remaining isomorphic across serialisations.</p>

                  <p id="human-and-machine-interpretable-units"><strong>Human and machine-interpretable units</strong>: As indicated earlier, the high-level units of communication that I am examining are primarily in the form of prose which may be accompanied with supplemental (meta)data. With this premise, I emphasise on the point that the underlying information is intended for <em>both</em> humans and machines, where each can create and interact with the information through applicable and desired interfaces.</p>

                  <p id="content-negotiation"><strong>Content negotiation</strong>: The HTTP <cite><a href="https://tools.ietf.org/html/rfc7231#section-3.4">Content Negotiation</a></cite> mechanism can be used to serve a possible representation of a resource that the client prefers from a URI. The decision algorithm may be based on different dimensions of content negotiation, eg. media type, character set, encoding, language, time. All things equal, here I consider having simplicity in the design as a desired quality for a server requirement, in order to make data available for the purpose of read-write operations that a client can perform. For instance, to what extent can we serve a resource representation "as is" without having to perform media type conversions in order to satisfy both human and machine consumers? By raising this, it is neither the case that a one-size-fits-all solution is required or desirable.</p>

                  <p id="rdfa"><strong>RDFa</strong>: From the available RDF syntaxes, this line of reasoning brings us to encapsulating information using <cite><a href="https://www.w3.org/TR/rdfa-core/">RDFa 1.1</a></cite> - attribute-level extension - inside host languages like (X)HTML, and various XML-family languages eg. SVG, MathML - language mixing. What makes <cite><a href="https://www.w3.org/TR/rdfa-in-html/">RDFa in HTML</a></cite>, for instance, an attractive combination is that it maps information patterns in RDF which is ideal for enhanced machine processing, while retaining the same document that is interpretable by humans. Essentially, interoperable information exchange and reuse by machines is intended to work over the RDF graph that is expressed and encoded with RDFa. Here HTML merely acts as the container to encapsulate the underlying information and to offer presentations and interactions (in regardless of the RDF syntax embedded in HTML). RDFa specifies only a syntax and allows independently defined specifications (like vocabularies) to be used. RDFa defines a single, non-domain-specific syntax, used alongside a hosting language's syntax, so that fragments of information can be consistently interpretable. Existing HTTP servers can virtually serve HTML content without additional server or client-side modules or application logic. Ergo, RDFa in HTML manifests a low barrier to make human and machine-interpretable information available from a single URL. The W3C TAG Finding <cite><a href="http://www.w3.org/2001/tag/doc/selfDescribingDocuments">The Self-Describing Web</a></cite> also posits RDFa in HTML as a good practice: <q cite="https://www.w3.org/2001/tag/doc/selfDescribingDocuments.html#UsingRDFa">To integrate HTML information into the self-describing Semantic Web, use RDFa.</q> Finally, W3C <cite><a href="https://www.w3.org/TR/xhtml-rdfa-scenarios/">RDFa Use Cases: Scenarios for Embedding RDF in HTML</a></cite> describes the <q cite="https://www.w3.org/TR/xhtml-rdfa-scenarios/#use-case-7">Augmented Browsing for Scientists</q> use case where actors can add RDFa to their articles to indicate the scientific components by reusing the existing vocabularies defined by the scientific community.</p>

                  <div class="note" id="rdf-in-html">
                    <h4>Note</h4>
                    <div>
                      <p>The initial motivation and development on encoding <q>RDF in HTML</q> started in the late 1990s and continued into early 2000, and eventually became the <cite><a href="https://www.w3.org/MarkUp/2004/rdf-a.html">RDF/A Syntax</a></cite> - currently known as RDFa - in 2004. The goal was to express RDF by using markup languages' attribute mechanisms alongside existing content so that documents can be more machine-readable. There has been a number of <cite><a data-versiondate="2018-04-07T08:20:30Z" data-versionurl="https://web.archive.org/web/20180407082030/http://infomesh.net/2002/rdfinhtml/" href="http://infomesh.net/2002/rdfinhtml/">RDF in HTML: Approaches</a></cite> which helped shape the initial version of RDFa, the surviving approach i) retained the expressiveness of the RDF language ii) and extending host languages (like HTML, SVG, MathML) through common attributes as necessary, iii) was aligned with the original vision of the Web, iv) was built through consensus through an open Web standards body like the W3C.</p>
                    </div>
                  </div>

                  <p id="why-rdfa"><strong>Why RDFa</strong>: HTML's extensibility mechanism allows authors to embed <q>data blocks</q> using the <code>&lt;script type=""&gt;</code> mechanism to include content in <a href="https://www.w3.org/TR/turtle/#in-html">Turtle</a>, <a href="https://www.w3.org/TR/json-ld/#embedding-json-ld-in-html-documents">JSON-LD</a>. Information in <code>script</code> are hidden from human view in native HTML interfaces until supplementary processing takes place. For information extraction to take place, the consumer needs to 1) process the HTML, 2) select the <code>script</code> node, 3) parse the content in RDF. On the other hand, RDFa can be included on any HTML tag, and so all human-visible content in HTML can be complemented with machine-readable counterparts in the same context node. This is optimal in avoiding data duplication in the same document which happens to be the case with the other serialisations in RDF, as well as avoiding any further intervention to synchronise data across different nodes. Having a single, unambiguous, and authoritative representation of the information as human-visible and marked as RDFa conforms to the <cite><a href="https://en.wikipedia.org/wiki/Don't_repeat_yourself">Don't Repeat Yourself</a></cite> (<abbr title="Don't Repeat Yourself">DRY</abbr>) principle. It is efficient in that it has no dependency on JavaScript, external or third-party applications to make the hidden machine-readable content be consumable from a human user interface - whereas HTML based user-agents can be expected to conform to <cite><a href="https://www.w3.org/TR/html5/editing.html">user interaction</a></cite> <cite><a href="https://www.w3.org/TR/html5/browsers.html">loading Web pages</a></cite> specification. For example, a <a href="https://en.wikipedia.org/wiki/Text-based_web_browser">text-based Web browsers</a> can access and allow interactions with documents. RDFa in HTML is all around a simple but effective design pattern that is able to serve both humans and machines without additional parts or machinery. With all things equal, having all content in HTML is optimal for Web-based archives, as well as helps towards meeting the <em>archiving</em> and <em>awareness</em> functions of scholarly communication.</p>

                  <p id="serialisations"><strong>Serialisations</strong>: Having the canonical representation for articles, annotations, and notifications in HTML+RDFa, still leaves the servers, if so desired, to provide alternative serialisations, eg. Turtle, and JSON-LD, depending on the <a href="#content-negotiation">content negotiation</a> with clients. Articles are represented in HTML+RDFa so that information is usable by both humans and machine consumers while maintaining lowest requirements for publishing, eg. a single URL with full content in HTML+RDFa can be accessible from any HTTP server. No additional requirements necessary from clients eg. JavaScript support and enabled, or servers eg. additional RDF based content negotiation.</p>

                  <p id="separation-of-concerns"><strong>Separation of concerns</strong>: By adopting the <cite>progressive enhancement</cite> (as described in <cite><a href="http://hesketh.com/publications/progressive_enhancement_and_the_future_of_web_design.html" rel="cito:citesAsRelated">Progressive Enhancement and the Future of Web Design</a></cite>) strategy for the structural (HTML+RDFa), presentational (CSS), and behavioural (JavaScript) layers, we can allow content and base functionality to be accessible through different media and devices. Ultimately, the unit of communication represented in HTML+RDFa can be accessible - readable - for both humans and machines without requiring any CSS or JavaScript. This approach is considered to cover the base requirement of making the content available with lowest server requirements, ie. practically, today any HTTP server that can serve HTML and a client that can consume HTML.</p>

                  <p id="affordance"><strong>Affordance</strong>: Hypertext has perceivable affordances in that both humans and machines can choose to act. For example, when a Web document is presented with a hyperlink, its users have the option to follow the link, if they so desire, by pressing a key on their keyboard, clicking on it with their pointing-device, or with voice activation and so on. Hovering a link with the cursor can trigger the Web browser to display the full target URL in the status bar of the application, and hence informing the user on what lies ahead before engaging further. If the user is already familiar with the link (visited earlier) or uninterested, they can skip. The interaction with the hypertext is in essence non-linear, ie. we can follow the links as far as we are able to, or interested, and then come back to where we started. Similarly, machines, like Web-crawlers are able to perform exactly the same process. Moreover, hyperlinks marked up with specific relations to their target reference can signal information that can effectively induce unique interactions. In that respect, RDFa in HTML for instance can help enrich and enable the structure for different interaction possibilities, for example though runtime JavaScript or the Web browser's built-in understanding of the underlying actions. With respect to scholarly referencing, hypertext can not only reference other resources - as typical to print-based expressions - but it can also link.</p>

                  <p id="units-with-unique-identifiers"><strong>Units with unique identifiers</strong>: Any <em>thing</em> that is deemed to be of importance can be identified on the Web with a URI as per <a href="scholarly-communication-on-the-web#axiom-0">Axiom 0: Universality 1</a>. Having globally unique identifiers for all sorts of objects at fine granularity facilitates precision for interlinked knowledge. We have the means to guide both human and machine users to better discover and exchange scientific and scholarly objects. Thereby making it possible to fulfil the <em>registration</em> function for virtually anything.</p>

                  <p id="markup-patterns"><strong>Markup patterns</strong>: HTML has several <cite><a href="http://w3c.github.io/html/single-page.html#design-notes-extensibility">extensibility mechanisms</a></cite>, eg. <code>class</code>, <code>data-*</code>, <code>rel</code> attributes, and <code>meta</code>, <code>script</code> elements to support vendor-neutral markup patterns. In addition to HTML's <cite><a href="http://w3c.github.io/html/infrastructure.html#infrastructure">common infrastructure</a></cite>, it is possible for documents to signal formal grammars, eg. HTML profiles and XML schemas, to announce the structure of documents such that the machine-processing instructions are well-defined; predetermined and fixed. In practice, grammars are used to help extract markup patterns according to specified definitions. Although <a href="https://www.w3.org/html/wg/wiki/DroppedAttributeProfile">profiles are no longer supported in HTML5</a>, they were originally intended to assign additional meaning that would otherwise remain local (private) to the document. For instance, <cite><a href="https://www.w3.org/TR/grddl/">Gleaning Resource Descriptions from Dialects of Languages</a></cite> (<abbr title="Gleaning Resource Descriptions from Dialects of Languages">GRDDL</abbr>) provided a way for custom <cite><a href="https://www.w3.org/TR/xslt/">XSL Transformations</a></cite> (<abbr title="XSL Transformations">XSLT</abbr>) to handle out-of-band transformation workflows, and to interpret the structure and semantics in the original document.</p>

                  <p id="formal-grammars"><strong>Formal grammars</strong>: While HTML markup with formal grammars has the quality of being efficient for cooperating systems, it comes at the cost of wider interoperability. That is, if an application is designed to <em>only</em> work with a particular flavour or subset of HTML, then it would not be able to work with arbitrary HTML documents on the Web. Hence, having profiles or grammars in and itself not an issue, however its <em>effects</em> are likely to be that they are less interoperable than they can be. This is in contrast to applications safely ignoring information patterns they do not understand or interested in using, even if they have their preferred internal grammars or HTML templates. From the consuming side, if the application's information <em>reuse</em> is dependent on HTML a specific schema or tree structure, effectively locks the application into coping with those patterns, and ultimately less flexible about handling expressions that the application is unfamiliar with. The effect is a constrained or a closed information system.</p>
                </div>
              </section>

              <section id="vocabularies" inlist="" rel="schema:hasPart" resource="#vocabularies">
                <h3 property="schema:name">Vocabularies</h3>
                <div datatype="rdf:HTML" property="schema:description">
                  <p>Here I describe a wide range of well-known Semantic Web vocabularies that can be used to model and describe units of communication. It is not intended to be an exhaustive list but to provide an overview on the kind of things that could be potentially described, anywhere from publishing articles, scholarly activities, to datasets holding scientific measurements.</p>

                  <p id="general-purpose"><strong>General purpose</strong>: <cite><a href="http://www.dublincore.org/documents/dcmi-terms/">DCMI Metadata Terms</a></cite> is used to describe digital and physical resources along with metadata on provenance and rights. <cite><a href="http://schema.org/">schema.org</a></cite> is composed of a common set of schemas that occurs in Web pages. These vocabularies are widely used on the Web and are generally domain agnostic, making them suitable to describe document-level concepts with respect to scholarly units.</p>

                  <p id="publishing-and-referencing"><strong>Publishing and referencing</strong>: <cite><a href="http://purl.org/ontology/bibo/">Bibliographic Ontology Specification</a></cite> and <cite><a data-versiondate="2018-10-04T08:40:13Z" data-versionurl="https://web.archive.org/web/20181004084013/http://www.sparontologies.net/" href="http://purl.org/spar">Semantic Publishing and Referencing Ontologies</a></cite> (<abbr title="Semantic Publishing and Referencing Ontologies">SPAR</abbr>) cover a wide range of concepts in the publishing domain while being agnostic about the types of content, eg. <q cite="http://purl.org/spar">document description, bibliographic resource identifiers, types of citations and related contexts, bibliographic references, document parts and status, agents' roles and contributions, bibliometric data and workflow processes</q>. <cite><a data-versiondate="2018-10-04T14:05:28Z" data-versionurl="https://web.archive.org/web/20181004140528/https://sparontologies.github.io/article/spar-iswc2018/" href="https://w3id.org/spar/article/spar-iswc2018/">The SPAR Ontologies</a></cite>, Peroni, 2018, describes ontologies for bibliographic resources and their parts (<a href="http://purl.org/spar/fabio" title="FRBR-aligned Bibliographic Ontology">FaBiO</a>, <a href="http://purl.org/spar/frbr">FRBR-DL</a>, <a href="http://purl.org/spar/doco">DoCO</a>, <a href="http://purl.org/spar/deo">DEO</a>, <a href="http://purl.org/spar/datacite">DataCite</a>); citations of scholarly resources (<a href="http://purl.org/spar/cito">CiTO</a>, <a href="http://purl.org/spar/biro">BiRO</a>, <a href="http://purl.org/spar/c4o">C4O</a>); publishing workflow (<a href="http://purl.org/spar/pro">PRO</a>, <a href="http://purl.org/spar/pso">PSO</a>, <a href="http://purl.org/spar/pwo">PWO</a>, <a href="http://purl.org/spar/scoro">SCoRO</a>, <a href="http://purl.org/cerif/frapo">FRAPO</a>); metrics and statistics for bibliographic resources (<a href="http://purl.org/spar/bido">BiDO</a>, <a href="http://purl.org/spar/fivestars">FiveStars</a>).</p>

                  <p id="knowledge-organisation"><strong>Knowledge Organisation</strong>: <cite><a href="https://www.w3.org/TR/skos-reference/">Simple Knowledge Organization System</a></cite> (<abbr title="Simple Knowledge Organization System">SKOS</abbr>) defines a common data model for structures like thesauri, taxonomies, classification schemes and subject heading systems in library and information sciences. SKOS is suitable to bridge different scientific communities to organise concepts by providing definitions, links, and possible mappings across collections.</p>

                  <p id="participation"><strong>Participation</strong>: Actors are integral to social Web activities and the four functions of scholarly communication. Generally speaking, agent - human or machine - profiles can be described with the <cite><a href="http://xmlns.com/foaf/0.1/">Friend of a Friend</a></cite> (<abbr title="Friend of a Friend">FOAF</abbr>) vocabulary to have a combination of what or who they are, what they have created, who they know, their memberships, and so forth. <cite><a href="http://rdfs.org/sioc/spec/">SIOC Core Ontology Specification</a></cite> provides concepts to describe information from online communities like weblogs, message boards, wikis, etc., as well as connections between their content items. <cite><a href="https://www.w3.org/TR/activitystreams-vocabulary/">Activity Vocabulary</a></cite> provides specific activity structures and types for objects and links (eg. article, event, place, mention), actors (eg. application, group, person, service) and for past, current or future social activities (eg. announce, create, like, invite, question). While the core vocabulary covers a wide range of activities, it can be extended to cover domain-specific scientific activities. The <cite><a href="https://www.w3.org/TR/annotation-vocab/">Web Annotation Vocabulary</a></cite> underpins the annotation model and is used to express information about a set of connected resources, typically conveying some sort of a relationship where the <q>body</q> of a resource is about the <q>target</q> resource. <cite><a href="https://www.w3.org/TR/annotation-html/">Embedding Web Annotations in HTML</a></cite> describes and illustrates potential approaches for including annotations within HTML documents using current specifications like RDFa or JSON-LD. <cite><a href="https://www.w3.org/TR/selectors-states/">Selectors and States</a></cite> describes the use of annotation Selectors as URI fragment identifiers relying on the formal specification and the semantics in the data model. Any resources can advertise a location where it can receive <cite><a href="https://www.w3.org/TR/ldn/">Linked Data Notifications</a></cite> for social activities eg. invitation to review an article, annotation being created. I describe LDN in detail later serving as one of the foundational components towards a decentralised and social Web. In order to indicate an agent's cognitive pattern within contexts, their temporal dynamics and their origins, <cite><a href="http://purl.org/ontology/cco/core#">The Cognitive Characteristics Ontology</a></cite> can be used eg. a human language competence.</p>

                  <p id="rights-and-responsibilities"><strong>Rights and Responsibilities</strong>: <cite><a href="http://creativecommons.org/ns">Creative Commons Rights Expression Language</a></cite> lets licenses to be described - jurisdiction, permissions, requirements, license and work properties - and having them attached to digital works. The <cite><a href="https://creativecommons.org/licenses/">Creative Commons licenses</a></cite> (<abbr title="Creative Commons">CC</abbr>) is intended to enable sharing and reuse of creative works and knowledge, by specifying how something - like scientific and scholarly resources - may be copied, distributed, edited, remixed, and built upon. The <cite><a href="https://www.w3.org/ns/odrl/2/">Open Digital Rights Language</a></cite> (<abbr title="Open Digital Rights Language">ODRL</abbr>) makes it possible to express permissions and obligations about the usage of content and services. <cite><a href="https://www.w3.org/TR/odrl-vocab/">ODRL Vocabulary &amp; Expression</a></cite> describes how to encode such policies.</p>

                  <p id="access-control-and-certificates"><strong>Access Control and Certificates</strong>: The <cite><a href="https://www.w3.org/wiki/WebAccessControl">Web Access Control</a></cite> (<abbr title="Web Access Control">WAC</abbr>) mechanism with the <cite><a href="https://www.w3.org/ns/auth/acl">Access Control List</a></cite> (<abbr title="Access Control List">ACL</abbr>) vocabulary describes authorization policies in particular to access and operations - read, write, append, control - that can be done on Web resources by agents or groups. <cite><a href="https://www.w3.org/ns/auth/cert">The Cert Ontology 1.0</a></cite> can be used to indicate digital certificate information for agents.</p>

                  <p id="provenance"><strong>Provenance</strong>: <cite><a href="https://www.w3.org/TR/prov-o/">The PROV Ontology</a></cite> (<abbr title="The PROV Ontology">PROV-O</abbr>) can be used <q>to represent and interchange provenance information generated in different systems and under different contexts</q>. It can be also be <q>specialized for modeling application-specific provenance details in a variety of domains</q>, like for instance <cite><a href="http://www.opmw.org/model/OPMW/">The OPMW-PROV Ontology</a></cite> to describe workflow traces and their templates, which also extends the <cite><a href="http://www.opmw.org/model/p-plan/">P-Plan Ontology</a></cite> that is designed to represent scientific processes. The <cite><a href="https://w3id.org/ro/">Wf4Ever Research Object Model</a></cite> is used to describe workflow-centric <cite>Research Objects</cite>: aggregations of resources along with annotations on those resources relating to scientific workflows. <cite><a href="https://www.w3.org/TR/verifiable-claims-data-model/">Verifiable Claims Data Model and Representations</a></cite> is aimed at expressing a claim; statement made by an entity about a subject, on the Web in a way that is cryptographically secure, privacy respecting, and automatically verifiable. <cite><a href="http://mementoweb.org/ns">The Memento terms vocabulary</a></cite> contains a set of terms for the <cite>Memento Framework</cite> to facilitate obtaining representation of resource states.</p>

                  <p id="design-lifecycle"><strong>Design Lifecycle</strong>: <cite><a href="https://w3id.org/dio">Design Intent Ontology</a></cite> can be used to <q>to capture the knowledge generated during various phases of the overall design lifecycle</q> like for instance the artefacts about software or technical specification requirements, issues, solutions, justifications and evidence.</p>

                  <p id="datasets"><strong>Datasets</strong>: For multi-dimensional statistical data, the <cite><a href="https://www.w3.org/TR/vocab-data-cube/">RDF Data Cube vocabulary</a></cite> can be used to both model the structure of the hypercube as well as aggregate data which uses its structure definition. The structure is typically an arbitrary number of components: dimensions that helps to identify an observation, and one or more measurements about the phenomenon being observed. The <cite><a href="http://rdf-vocabulary.ddialliance.org/discovery.html">DDI-RDF Discovery Vocabulary</a></cite> (<abbr title="DDI-RDF Discovery Vocabulary">Disco</abbr>) enables publishing and discovery of metadata about datasets like research and survey data. Disco is generally concerned with microdata descriptions that is on a lower level of aggregation than the RDF Data Cube. It is not intended to represent the data itself, but only its structure, where the record-level raw data in its original format is only referenced. Disco also enables a way to describe the aggregation methods that was used to collect the data. The <cite><a href="https://www.w3.org/TR/vocab-ssn/">Semantic Sensor Network Ontology</a></cite> (<abbr title="Semantic Sensor Network">SSN</abbr>) can be used for <q>describing sensors and their observations, the involved procedures, the studied features of interest, the samples used to do so, and the observed properties, as well as actuators</q>. <cite><a href="https://www.w3.org/TR/void/">Describing Linked Datasets with the VoID Vocabulary</a></cite> (<abbr title="Vocabulary of Interlinked Datasets">VoID</abbr>) is concerned with metadata about RDF datasets to help with deployment, discovery of data and services, cataloguing and archiving of RDF datasets, as well as linksets between datasets. <cite><a href="https://www.w3.org/TR/EARL10-Schema/">Evaluation and Report Language</a></cite> (<abbr title="Evaluation and Report Language">EARL</abbr>) can be used to describe the test results and facilitate their exchange between applications. It provides reusable terms for generic quality assurance and validation purposes.</p>

                  <p id="scientific-expressions"><strong>Scientific expressions</strong>: <cite><a href="http://sio.semanticscience.org/">Semanticscience Integrated Ontology</a></cite> can be used to describe scientific experiments, for example including their procedure, hypothesis, objectives, study design, analysis, and observations. <cite><a href="http://purl.obolibrary.org/obo/stato.owl">STATO: the statistical methods ontology</a></cite> covers statistical methods, tests, conditions of application, results, as well as aspects of experimental design and descriptions. <cite><a href="http://nanopub.org/guidelines/working_draft/">Nanopublications</a></cite> helps to publish scientific assertions that can be uniquely identified with associated context, attributed to their author, as well as help to preserve associated provenance. <cite><a href="http://purl.org/mp/value">Micropublications</a></cite> can be used to formalise the arguments and evidence in scientific publications.</p>

                  <p id="software-projects"><strong>Software Projects</strong>: <cite><a href="http://usefulinc.com/">Description of a Project</a></cite> (<abbr title="Description of a Project">DOAP</abbr>) can be used to describe (open source) software projects like their repositories, bug databases, maintainers, technical specifications they implement, programming languages they use or the platform they run on.</p>
                </div>
              </section>


              <section id="accessibility-usability-inclusion" inlist="" rel="schema:hasPart" resource="#accessibility-usability-inclusion">
                <h3 property="schema:name">Accessibility, Usability, and Inclusion</h3>
                <div datatype="rdf:HTML" property="schema:description">
                  <p>We acknowledge the diversity of people using the Web, not only the actors in scholarly communication, but anyone that may create or reuse information. Our aim is to have inclusive designs for wide range of people and their abilities. I outline and borrow key initiatives and solutions on content accessibility, accessible applications, authoring tools, and internationalisation. I refer to <q>accessibility</q> (<abbr title="Accessibility">a11y</abbr>) in the widest sense that any agent; human, machine, or other can effectively access information and participate.</p>

                  <p id="web-content-accessibility"><strong>Web Content Accessibility</strong>: The accessibility of units of communications can also be seen as an aim for all-inclusive design that is usable by humans with widest possible range of abilities and situations. For this, I defer to W3C's <cite><a href="https://www.w3.org/TR/WCAG/">Web Content Accessibility Guidelines</a></cite> (<abbr title="Web Content Accessibility Guidelines">WCAG</abbr>) to cover an array of recommendations to make content accessible to a wider range of people regardless of any disability, limitation, or sensitivity, through different media and interfaces. The goal is to provide a reliably mutually consistent expression of the content. For human-centric scholarly communication to thrive, units of communication should be targeted to aim to meet highest level of conformance criteria. W3C WCAG 2.1 provides a range of guidelines that can be adopted for better content accessibility:</p>

                  <blockquote cite="https://www.w3.org/TR/WCAG21/">
                    <dl>
                      <dt>Perceivable</dt>
                      <dd>Information and user interface components must be presentable to users in ways they can perceive.</dd>
                      <dt>Operable</dt>
                      <dd>User interface components and navigation must be operable.</dd>
                      <dt>Understandable</dt>
                      <dd>Information and the operation of user interface must be understandable.</dd>
                      <dt>Robust</dt>
                      <dd>Content must be robust enough that it can be interpreted by a wide variety of user agents, including assistive technologies.</dd>
                    </dl>
                    <footer><cite><a href="https://www.w3.org/TR/WCAG21/">Web Content Accessibility Guidelines (WCAG) 2.1</a></cite>, W3C</footer>
                  </blockquote>


                  <p id="accessible-rich-internet-applications"><strong>Accessible Applications</strong>: The W3C <cite><a href="">Accessible Rich Internet Applications</a></cite> (<abbr title="Accessible Rich Internet Applications">WAI-ARIA</abbr>) recommendation provides an ontology to help assistive technologies to provide a consistent user interface and understanding of the objects. Host languages like HTML and SVG can include the ARIA ontology: <q>roles</q> to alert the purpose of an element; <q>properties</q> to indicate an elements relationship to other things; <q>states</q> to indicate what the element is doing, as well as alerting users about changes in state. ARIA helps to inform consuming assistive technologies such as screen magnifiers, screen readers, text-to-speech software, speech recognition software, alternate input technologies, and alternate pointing devices to create a particular accessibility tree, and to adapt the user interface to a form that works for the person, eg. a screen-reader can read the menu items, or selected option is receiving keyboard focus. WAI-ARIA is extensible and has a number of accessible API mappings. <cite><a href="https://www.w3.org/TR/dpub-aria/">Digital Publishing WAI-ARIA Module 1.0</a></cite> (<abbr title="Digital Publishing WAI-ARIA Module">DPUB-ARIA</abbr>) specialises WAI-ARIA's ontology to enable semantic navigation, styling and interactive features in context of digital publishing. <cite><a href="https://www.w3.org/TR/graphics-aria/">WAI-ARIA Graphics Module</a></cite> is another extension of WAI-ARIA aimed to support structured graphics such as charts, graphs, technical drawings and scientific diagrams, to assistive technologies in order improve accessibility of graphics or diagrams through detailed annotations.</p>


                  <p id="authoring-tool-accessibility"><strong>Authoring Tool Accessibility</strong>: In order to contribute to the proliferation of Web content that is accessible to a broad range of people, authoring tools would need to be accessible as well. The W3C <cite><a href="https://www.w3.org/TR/ATAG/">Authoring Tool Accessibility Guidelines</a></cite> (<abbr title="Authoring Tool Accessibility Guidelines">ATAG</abbr>) is a recommendation to assist with the design of authoring tools. The guidelines have a success criteria covering two areas:</p>

                  <blockquote cite="http://www.w3.org/TR/ATAG20/#guidelines">
                    <ul>
                      <li>Make the authoring tool user interface accessible</li>
                      <li>Support the production of accessible content</li>
                    </ul>
                    <footer><cite><a href="http://www.w3.org/TR/ATAG20/#guidelines">ATAG 2.0 Guidelines</a></cite>, W3C</footer>
                  </blockquote>

                  <p id="user-agent-accessibility-guidelines"><strong>User Agent Accessibility Guidelines</strong>: To support the general principles for the development of accessible user agents, ie. <q>any software that retrieves, renders and facilitates end-user interaction with web content</q>, the W3C <cite><a href="https://www.w3.org/TR/UAAG20/">User Agent Accessibility Guidelines</a></cite> (<abbr title="User Agent Accessibility Guidelines">UUAG</abbr>) specifies three layers of guidance for developers to integrate:</p>

                  <ul>
                    <li>overall principles: perceivable, operable, understandable, programmatic access, specifications and conventions;</li>
                    <li>general guidelines to provide a framework to make user agents more accessible to users with disabilities;</li>
                    <li>and success criteria in order to test conformance</li>
                  </ul>

                  <p id="internationalization-and-localization"><strong lang="en-us" xml:lang="en-us">Internationalization and Localization</strong>: Adaptability of content and software to the needs of target audiences helps towards accessibility. For example, the mechanisms to cater information and interfaces so that people from any culture, region, or language preference can participate better. The W3C <cite><a href="https://www.w3.org/International/">internationalization</a></cite> (<abbr title="Internationalization">i18n</abbr>) and <cite><a href="https://www.w3.org/International/questions/qa-i18n#l10n">localization</a></cite> (<abbr title="Localization">l10n</abbr>) initiatives and best practices helps towards this end. Internationalization refers to the design and development of mechanisms so that adaptable localization can take place in users' environment.</p>

                  <p id="internationalization">Internationalization of Web content and technologies is intended to make it possible for people to use them with different languages, scripts, and cultures. For example, content authors can:</p>
                  <ul>
                    <li>include links to navigate to different languages of the content;</li>
                    <li>declare the base language of a document, indicate multiple languages and their directional flow - to help with translations;</li>
                    <li>use Unicode character encoding, eg. UTF-8, in data forms and text to ensure correct effects;</li>
                    <li>check and minimise inappropriate cultural bias, and improve translatability;</li>
                    <li>restrict markup use to structure and semantics.</li>
                  </ul>

                  <p id="localization">The localization of content would mean that user's preferred (or acceptable) visual design can be presented. For instance, human-readable numeric, date and time formats can be adapted to what we are familiar with; symbols, icons, and colours can be anywhere from what's culturally acceptable, familiar or comfortable for us to use; text and graphics can be normalised or transformed to minimise misinterpretation.</p>
                </div>
              </section>

              <section id="archivability" inlist="" rel="schema:hasPart" resource="#archivability">
                <h3 property="schema:name">Archivability</h3>
                <div datatype="rdf:HTML" property="schema:description">
                  <p id="archivability">Archivability of Web resources <q cite="http://library.stanford.edu/projects/web-archiving/archivability">refers to the ease with which the content, structure, functionality, and front-end presentation(s) of a website can be preserved and later re-presented, using contemporary web archiving tools</q>.</p>

                  <p id="website-archivability">In <cite><a data-versiondate="2018-02-05T14:49:35Z" data-versionurl="https://web.archive.org/web/20180205144935/http://purl.pt/24107/1/iPres2013_PDF/CLEAR%20a%20credible%20method%20to%20evaluate%20website%20archivability.pdf" href="http://purl.pt/24107/1/iPres2013_PDF/CLEAR%20a%20credible%20method%20to%20evaluate%20website%20archivability.pdf">CLEAR: a credible method to evaluate website archivability</a></cite>, Banos, 2013 posit that Web archivability can be measured by five facets: <q>accessibility</q> as network access to content; <q>standards compliance</q> in terms of information using common open formats and specifications; <q>cohesion</q> as information being independent of external support; the level of <q>metadata</q> that is available alongside the content; and, server's <q>performance</q>. Such facets can be used to quantify website archivability.</p>

                  <p id="archivability-rule-of-thumb">In the Web development community, a rule of thumb to improve archivability of Web content is to aim for general standards compliance and content accessibility. In the case of standards compliance, well-formed and valid markup ensures internal integrity of Web documents. As for better accessibility, incorporating WCAG where applicable can help user-agents, including text-only Web browsers, Web crawlers, and other agents with minimal capabilities to parse and render content. With respect to traditional Web documents, the information that is visible, observable, or human-readable from HTML is considered to set the lowest barrier to obtain content. As CSS and JavaScript are concerned with presentation and behavioural layers respectively, they play a secondary role towards archiving of "content".</p>

                  <p id="archivability-javascript"><cite><a data-versiondate="2018-09-25T17:12:30Z" data-versionurl="https://web.archive.org/web/20180925171230/https://www.cs.odu.edu/~mln/pubs/ijdl-archivability-2015.pdf" href="https://www.cs.odu.edu/~mln/pubs/ijdl-archivability-2015.pdf">The impact of JavaScript on archivability</a></cite>, Brunelle, 2015, study the quality of archived Web resources (based on URIs from Twitter and Archive-It) and report that JavaScript-driven content played a significant role in the reduction of preservation and recall of content. For example, resources referring to external scripts may load unsuccessfully given that their own independent availability. Authors refer to the notion of <q>deferred representations</q> where the final state of a resource is when all code and events have finished executing. Hence, representations rely on JavaScript to fully render do not serve well for archival crawlers that are unequipped to handle JavaScript. On the other hand, certain archival services include a feature known as <em>headless browser</em> that is capable of processing the resource similar to common GUI-based Web browsers with JavaScript enabled, and thus capturing the final state of the representation once all scripts are executed. This too however may be problematic for content that dynamically changes based on the instructions of the script. For example, a script that presents temporal content may be different at each time the archived resource is recalled.</p>

                  <p id="archivability-accuracy">While evaluation services like <cite><a href="http://archiveready.com/">ArchiveReady</a></cite> check for website archivability based on the five metrics, it is not able to determine the <em>accuracy</em> of intended information. As the content in the HTML representation and the state of rendered content (after script execution) may differ, their delta can be compared to what is intended for archiving. In <cite><a data-versiondate="2018-09-25T21:26:35Z" data-versionurl="https://web.archive.org/web/20180925212635/https://www.planets-project.eu/docs/papers/Dappert_Significant_Characteristics_ECDL2009.pdf" href="https://www.planets-project.eu/docs/papers/Dappert_Significant_Characteristics_ECDL2009.pdf">Significance is in the Eye of the Stakeholder</a></cite>, Dappert, 2009, contend that a stakeholder can specify the characteristics of resource representations and the conditions for preservation. For human-readable documents, it can be reasoned that the rendered content is what is intended for archiving by the publisher.</p>
                </div>
              </section>
            </div>
          </section>

          <section id="existing-markup-patterns" inlist="" rel="schema:hasPart" resource="#existing-markup-patterns">
            <h2 property="schema:name">Existing Markup Patterns</h2>
            <div datatype="rdf:HTML" property="schema:description">
              <p>There are plethora of approaches and developments to representing scholarly information with markup languages. Here I focus on a few and describe their characteristics.</p>

              <p id="jats"><cite><a href="http://jats.niso.org/">Journal Article Tag Suite</a></cite> (<abbr title="Journal Article Tag Suite">JATS</abbr>) is an XML format used to describe content and metadata of research and non-research articles eg. including reviews, editorials, instructions to authors. It can be used by publishers and archives to interchange scholarly content in a uniform way. The intent of its Tag Suite is to prescribe and to preserve the structure and semantics of the original content independent of the presentation. JATS includes three Tag Sets: journal archive and interchange, journal publishing, and article authoring. In the case of peer-reviewed scholarly articles that are intended to be archived, the publication may also include information about the conference the research was presented at, data about the publication and journal, document history, license, funding, and various kinds of annotations. Given that JATS is XML-based, different manifestations of the original content are generated through transformations eg. as a print-version, HTML, as well as RDF as described in <cite><a data-versiondate="2018-10-01T20:22:29Z" data-versionurl="https://web.archive.org/web/20181001202229/https://www.ncbi.nlm.nih.gov/books/NBK100491/" href="https://www.ncbi.nlm.nih.gov/books/NBK100491/">From Markup to Linked Data: Mapping NISO JATS v1.0 to RDF using the SPAR (Semantic Publishing and Referencing) Ontologies</a></cite>.</p>

              <p id="tei"><cite><a href="http://www.tei-c.org/">Text Encoding Initiative</a></cite> (<abbr title="Text Encoding Initiative">TEI</abbr>) has guidelines to <q cite="http://www.tei-c.org/guidelines/">define and document a markup language for representing the structural, renditional, and conceptual features of texts.</q> TEI is similar to JATS in that it aims to improve understanding of text made explicit with XML, as well as for information interchange, integration, and preservation. Its encoding methods are mainly aimed at machine-readable texts in academic, linguistic, literary and technical documents. Its document structure is similar to JATS in that it has a front (header), body (article), and back pattern, and including a generalistic approach to coping with text with any size, complexity, writing system, language, date, or media. For instance, the specification helps with information identification (eg. page numbers), structural divisions, pictures and diagrams with captions; different writing modes (eg. prose, verse); each with formal structural units (eg. paragraphs, lists, stanzas); with textual distinctions (eg. titles, names, quotations); as well as metatextual indications (eg. corrections, annotations, revisions).</p>

              <p id="epub"><cite><a href="http://www.idpf.org/epub">Electronic Publication</a></cite> (<abbr title="Electronic Publication">EPUB</abbr>) is implemented as a distribution and interchange format based on XML and Web Standards. EPUB is delivered as an archive file (ZIP) packaging XHTML, CSS SVG, along with supporting media files. The <cite><a data-versiondate="2018-09-20T12:03:37Z" data-versionurl="https://web.archive.org/web/20180920120337/http://www.idpf.org/epub/31/spec/epub-contentdocs.html" href="http://www.idpf.org/epub3/latest/contentdocs">EPUB Content Documents</a></cite> defines profiles - inheriting XHTML and extensions to the underlying document model - for the content to be used in the context of EPUB Publications, and <cite>EPUB Open Container Format</cite> defines the file format and processing model for the single-file that encapsulates all material. Software on devices complying with EPUB can read and interact with its content. It retains the reflowable features of XHTML and CSS in that content presentation can be adapted by a consuming device. The specification allows embedding of RDFa attributes.</p>

              <p id="rash"><cite><a data-versiondate="2017-10-02T17:17:56Z" data-versionurl="https://web.archive.org/web/20171002171756/https://essepuntato.github.io/papers/rash-peerj2016.html" href="https://w3id.org/people/essepuntato/papers/rash-peerj2016.html">Research Articles in Simplified HTML</a></cite> (<abbr title="Research Articles in Simplified HTML">RASH</abbr>) is a format accompanied with the RASH Framework <q>for writing HTML-based scholarly papers</q>. RASH aims at sharing scholarly documents through the Web while working within the existing publishing workflow, and is expected to be produced from MS Word, ODT and LaTeX sources. RASH has been developed as a formal grammar using RelaxNG which includes <abbr title="a, blockquote, body, code, em, figcaption, figure, h1, head, html, img, li, link, math, meta, ol, p, pre, q, script, section, span, strong, sub, sup, svg, table, td, th, title, tr, ul">32 elements from HTML5</abbr>. With the exception of the <code>script</code> element, it is compiled of printable elements. Its grammar facilitates RASH documents to run against a markup validator, to convert between sources, rendering for Web and print media, and to extract additional semantics. Its rationale for representing human-visible and machine-readable information in HTML varies eg. title, authors, keywords of an article are used as hidden metadata, and require additional processing to make it human-visible in the Web browser, as such a dependency on JavaScript support and being enabled. The resulting grammar favours simplicity towards authoring over expressing accurate or appropriate semantics eg. <code>h1</code> for all heading levels is used, as opposed to HTML5's required heaving levels (<samp>hX</samp>). The format allows DPUB-ARIA and RDFa annotations, as well as embedding JSON-LD, Turtle, and RDF/XML data islands with the <code>script</code> element.</p>

              <p id="scholarly-html"><cite><a href="https://www.w3.org/community/scholarlyhtml/">W3C Scholarly HTML Community Group</a></cite> has its mission to build a common, open format for the exchange of scholarly information. Its specification on <cite><a data-versiondate="2017-10-02T17:15:58Z" data-versionurl="https://web.archive.org/web/20171002171558/https://w3c.github.io/scholarly-html/" href="https://w3c.github.io/scholarly-html/">Scholarly HTML</a></cite> proposes a vernacular document format aimed at encoding <em>scholarly articles</em> built on open standards, as well as having them compatible with off-the-self Web browsers. One of its high-level goals is to enable structured metadata as well as semantic enrichments, accessibility, internationalisation. It applies the notion of <q>semantic overlays</q> for its markup patterns with focus on role-based semantics as defined in WAI-ARIA, DPUB-ARIA, and semantic representations using RDFa. The - work-in-progress - specification explains how concepts for people and organisation, article semantics, schema roles, actions, citations, document rights, and so forth can be marked using appropriate vocabularies, using <cite><a href="https://schema.org/">schema.org</a></cite> as base. In order to simplify authoring, where applicable, it is encouraged to use RDFa markup patterns where the depth (level of nesting in the DOM tree) for the RDF statements would be relatively flat. One consequences of this rule of thumb may be that there can be duplicate information or parts of the information being human-visible whereas some others would be intended only for machine use.</p>

              <p id="existing-markup-patterns-characteristics"><strong>Summary of Characteristics</strong>: For historical and technical reasons, here I summarise some of their (shared) characteristics:</p>

              <ul>
                <li>With the exception of <cite>Scholarly HTML</cite>, the markup methods first cater to printability (as opposed to being Web-centric) or require transformations to other formats in order to be viewed and interacted further.</li>
                <li>Data representations are prescriptive in that they are coupled with specific applications or workflows.</li>
                <li>The generation or use of markup is dependent on specific environments for use or interchange, media or devices.</li>
                <li>The structure of the information is scoped to general-purpose scholarly documents, as opposed to for example encapsulating social (scholarly) Web activities.</li>
                <li>The structure and semantics of information is fundamentally based on HTML or XML (as opposed to the RDF language).</li>
                <li>In some cases, there is information duplicity as human and machine consumers are served with different data.</li>
                <li>There are post-processing dependencies (eg. via JavaScript execution) in order to turn hidden metadata into visible and readable by humans.</li>
              </ul>
            </div>
          </section>

          <section id="linked-statistics" inlist="" rel="schema:hasPart" resource="#linked-statistics">
            <h2 property="schema:name">Linked Statistics</h2>
            <div datatype="rdf:HTML" property="schema:description">
              <p>Research data in the form of observational or experimental data follows a different structure than narrative content - which is a common characteristic of a research article, annotation, notification or a profile. Structured data may be (semi-)automatically aggregated through instruments, stored, and viewed in different ways.</p>

              <p>As pointed out in <cite><a href="http://csarven.ca/statistical-linked-dataspaces">Statistical Linked Dataspaces</a></cite>, 2012, Capadisli, what linked statistics provide, and in fact enable, are queries across datasets: Given that the dimension concepts are interlinked, one can learn from a certain observation's dimension value, and enable the automation of cross-dataset queries. Moreover, domain-specific user interfaces can be built based on federated queries as discussed in <cite><a href="#linked-statistical-data-analysis">Linked Statistical Data Analysis</a></cite> in <cite><a href="decentralised-linked-research-application#sparqlines">Sparqlines</a></cite>.</p>

              <section id="linked-sdmx-data" inlist="" rel="schema:hasPart" resource="#linked-sdmx-data">
                <h3 property="schema:name">Linked SDMX Data</h3>
                <div datatype="rdf:HTML" property="schema:description">
                  <p>As statistical data is inherently highly structured and comes with rich metadata (in form of code lists, data cubes etc.), the application of the Linked Data design patterns is inherently suitable for representation and reuse on the Web. There exists no simple, standardised or (semi)automated way to transform statistical data into Linked Data since the raw data comes in different shapes and forms.</p>

                  <p>While access to statistical data in the public sector has increased in recent years, a range of technical challenges makes it difficult for data consumers to take advantage at ease. These are particularly related to the following two areas:</p>

                  <ul>
                    <li>Automation of data transformation of data from high profile statistical organizations.</li>
                    <li>Minimisation of third-party interpretation of the source data and metadata and lossless transformations.</li>
                  </ul>

                  <p><cite><a href="http://www.iso.org/iso/catalogue_detail.htm?csnumber=52500">Statistical Data and Metadata eXchange</a></cite> (<abbr title="Statistical Data and Metadata eXchange">SDMX</abbr>) is an ISO standard which provides the possibility to consistently carry out data flows between publishers and consumers. SDMX-ML (using XML syntax) is considered to be the gold standard for expressing statistical data. It has a highly structured mechanism to represent statistical observations, classifications, and data structures. Given that SDMX is arguably the most widely used standard for statistical data exchange (among statistical agencies and others), a great amount of statistical data about our societies is yet to be discoverable and identifiable through the open Web platform. Development teams often face low-level repetitive data management tasks to deal with someone else's data. Within the context of Linked Data, one aspect is to transform this raw statistical data eg. SDMX-ML, into an RDF representation in order to be able to use publicly available data in a uniform way.</p>

                  <p><cite><a href="http://csarven.ca/linked-sdmx-data">Linked SDMX Data</a></cite>, Capadisli, 2013, ie. my colleagues and I, contribute as follows:</p>

                  <ul>
                    <li>an approach for transforming SDMX-ML based on XSLT 2.0 templates and the implementation which transforms SDMX-ML data to RDF/XML</li>
                    <li>The extract, transform, load <abbr title="Extract Transform Load">ETL</abbr> process: a) retrieval of SDMX-ML data from APIs, b) their transformations to RDF/XML, and c) enrichment, d) storage in an RDF data store, and e) publicly accessible Linked Data publication based on the statistical data from the following agencies:
                      <ul>
                        <li><cite><a href="http://abs.270a.info/">Australian Bureau of Statistics</a></cite> (<abbr title="Australian Bureau of Statistics">ABS</abbr>)</li>
                        <li><cite><a href="http://www.bfs.admin.ch/">Swiss Federal Statistical Office</a></cite> (<abbr lang="de" title="Bundesamt für Statistik" xml:lang="de">BFS</abbr>)</li>
                        <li><cite><a href="http://www.bis.org/">Bank for International Settlements</a></cite> (<abbr title="Bank for International Settlements">BIS</abbr>)</li>
                        <li><cite><a href="http://www.ecb.int/">European Central Bank</a></cite> (<abbr title="European Central Bank">ECB</abbr>)</li>
                        <li><cite><a href="http://www.fao.org/">Food and Agriculture Organization of the United Nations</a></cite> (<abbr title="Food and Agriculture Organization of the United Nations">FAO</abbr>)</li>
                        <li><cite><a href="http://www.federalreserve.org/">Federal Reserve Board</a></cite> (<abbr title="Federal Reserve Board">FRB</abbr>)</li>
                        <li><cite><a href="http://www.imf.org/">International Monetary Fund</a></cite> (<abbr title="International Monetary Fund">IMF</abbr>)</li>
                        <li><cite><a href="http://www.oecd.org/">Organisation for Economic Co-operation and Development</a></cite> (<abbr title="Organisation for Economic Co-operation and Development">OECD</abbr>)</li>
                        <li><cite><a href="http://www.uis.unesco.org/">UNESCO Institute for Statistics</a> (<abbr title="UNESCO Institute for Statistics">UIS</abbr>)</cite></li>
                      </ul>
                    </li>
                  </ul>

                  <p>Each Linked Statistical Data (<abbr title="Linked Statistical Data">LSD</abbr>) endpoint:</p>

                  <ul>
                    <li>modeled using RDF, RDFS, XSD, OWL, XSD, DC Terms for general purpose descriptions; the RDF Data Cube vocabulary to describe multi-dimensional statistical data; PROV-O is used for provenance coverage; SKOS and XKOS to cover concepts, concept schemes and their relationships to one another;</li>
                    <li>cross dataset and concept scheme interlinking;</li>
                    <li>uniquely identifiable provenance level information at retrieval, transformation, and post-processing phases;</li>
                    <li>licensed under CC0 1.0 Universal Public Domain Dedication;</li>
                    <li>follows a URI template, where the URIs are versioned with respect to the original data counterparts</li>
                    <li>data dumps;</li>
                    <li>queryable SPARQL endpoint;</li>
                  </ul>

                  <p>The results are part of the <cite><a href="http://270a.info/">270a.info</a></cite> LSD Cloud which also includes data originally from <cite><a href="http://worldbank.org/">World Bank</a></cite> (<abbr title="World Bank">WB</abbr>) and <cite><a href="http://transparency.org/">Transparency International</a></cite> (<abbr title="Transparency International">TI</abbr>). The LSD Cloud is also part of the broader <cite><a href="http://lod-cloud.net/">Linked Open Data</a></cite> (<abbr title="Linked Open Data">LOD</abbr>) Cloud.</p>

<!--
                  <p><span class="todo"> At this point in time, the cloud is composed of X number of triples, where Y are statistical observations aggregated by statistical agencies.</span> Figure <a href="#interlinks-270a.info">interlinks-270a.info</a> is an overview of the LSD Cloud with interlinks across endpoints.</p>
-->

                  <figure id="interlinks-270a.info">
                    <object data="http://270a.info/media/images/270a.cloud.svg" height="480" type="image/svg+xml" width="640"></object>
                    <figcaption>Interlinks of Linked Statistical Data endpoints at 270a.info</figcaption>
                  </figure>

                  <p>What the LSD Cloud enables is that highly structured and interlinked statistical data and classifications that can be queried and used by decentralised applications.</p>
                </div>
              </section>

              <section id="linked-statistical-data-analysis" inlist="" rel="schema:hasPart" resource="#linked-statistical-data-analysis">
                <h3 property="schema:name">Linked Statistical Data Analysis</h3>
                <div datatype="rdf:HTML" property="schema:description">
                  <p>In <cite><a href="http://csarven.ca/linked-statistical-data-analysis">Linked Statistical Data Analysis</a></cite>, Capadisli, 2013, puts forward an approach based on decentralised (and federated) structured queries to retrieve statistical data from various SPARQL endpoints, conducting various data analyses (eg. regression analysis), and providing the results of the analysis as Linked Data back to the user. The system demonstrating the mechanism stores the analysis in RDF to enable future discovery and reuse eg. researchers looking up statistically significant results based on a set of indicators for a specific reference area. As a result, distributed linked statistics with accompanying provenance data can be more easily explored and analysed by interested parties.</p>

                  <p>The approach expects that the data is modelled using the RDF Data Cube vocabulary and is <cite><a href="http://www.w3.org/TR/vocab-data-cube/#wf">well-formed</a></cite>. Essential checks for integrity constraints include: 1) a unique data structure definition (DSD) is used for a dataset, 2) the DSD includes a measure (value of each observation), 3) concept dimensions have code lists, and 4) codes are from the code lists.</p>

                  <p>In order to compare variables in observations across statistical datasets, there needs to be an agreement on the concepts that are being matched for in respective observations. In the case of regression analysis, the primary concern is about reference areas (ie. locations), and making sure that the comparison made for the observations from dataset<sub>x</sub> (independent variable) and dataset<sub>y</sub> (dependent variable) are using concepts that are interlinked (using the property <code>skos:exactMatch</code>). Practically, a concept eg. Switzerland, from at least one of the dataset's code lists should have a relation to the other dataset's concept. It ensures that there is a reliable degree of confidence that the particular concept is interchangeable or the degree in which the concepts being comparable. Hence, the measure corresponding to the phenomenon being observed, is about the same location in both datasets. To this end, concepts in the datasets were interlinked.</p>

                  <p>In order to foster trust and confidence for data consumers (human and machine), the analysis is accompanied with provenance data. The analysis includes a <cite><a href="https://www.w3.org/DesignIssues/UI#OhYeah">Oh yeah?</a></cite> reference (in HTML as well as in RDF serializations) intended to guide the data consumer to a resource about the provenance activity - using the PROV-O vocabulary - about the performed analysis. These previously generated provenance activities provide links to all data sources which were used for the analysis, query construct for data aggregation, as well as metadata about the used tools, assigned license, production timestamps, and responsible agents for the generated analysis. Thus, in addition to analysis metadata, the user is able to track the data all the way back to its origins (at the statistical agencies), and reproduce or compare their results.</p>

                  <p>The proposed approach focuses on the scalability of the system with minimal human intervention. That is, new statistical dataset can be independently published while being expressed with relevant statistical vocabularies, and sufficient interlinks between concepts, then applications can discover them and perform queries in a uniform way. Hence, applications <em>only</em> need to be made aware of the location of new datasets.</p>
                </div>
              </section>

              <hr />

              <p id="enabling-scientific-data-on-the-web"><cite><a href="https://www.era.lib.ed.ac.uk/bitstream/handle/1842/9957/Milowski2014.pdf">Enabling Scientific Data on the Web</a></cite>, 2014, Miłowski, focuses on <q>enabling scientific data to exist on the Web in such a way that it can be processed both as viewable content and consumed data</q>. Miłowski posits that in order to enable user interactions through the Open Web Platform while having the same information machine-readable, <q>data must to be partitioned into “Web-sized” representations</q>. This can be contrasted with the approaches mentioned from earlier where the data is treated as "as is" without being structured in any particular way for applications to consume.</p>

              <p>In this thesis I describe and exemplify multiple implementation approaches. For instance, the tabular data about <a href="decentralising-scholarly-communication#specifications-for-forces-and-functions">Specifications to fulfil forces and functions in scientific communication</a>, tables in <a href="linked-data-notifications#comparison-of-notification-mechanisms">comparison of notification mechanisms</a>, <a href="linked-data-notifications#linked-data-notifications-implementations">linked data notifications implementations</a>, and in <a href="#decentralised-linked-research-application">decentralised linked research application</a>, as well as the data in <a href="#linked-specifications-reports">Linked Specifications, Test Suites, and Implementation Reports</a> are both human and machine-readable. Whereas in <a href="decentralised-linked-researc-application#sparqlines">Sparqlines</a>, I will discuss how SPARQL queries can be executed by client-side applications in an article authoring environment to fetch live data from remote endpoints, and be compiled into an SVG representation with embedded RDFa.</p>
            </div>
          </section>

        </div>
      </article>
    </main>
  </body>
</html>
